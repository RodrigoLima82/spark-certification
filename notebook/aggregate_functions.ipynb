{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Aggregate Functions\n",
    "\n",
    "- approx_count_distinct\n",
    "- avg\n",
    "- collect_list\n",
    "- collect_set\n",
    "- countDistinct\n",
    "- count\n",
    "- grouping\n",
    "- first\n",
    "- last\n",
    "- kurtosis\n",
    "- max\n",
    "- min\n",
    "- mean\n",
    "- skewness\n",
    "- stddev\n",
    "- stddev_samp\n",
    "- stddev_pop\n",
    "- sum\n",
    "- sumDistinct\n",
    "- variance, var_samp, var_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"example-08\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Raman        |Finance   |CA   |99000 |40 |24000|\n",
      "|Scott        |Finance   |NY   |83000 |36 |19000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
    "              (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n",
    "              (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n",
    "              (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n",
    "              (\"Raman\",\"Finance\",\"CA\",99000,40,24000),\n",
    "              (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n",
    "              (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n",
    "              (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n",
    "              (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000)]\n",
    "\n",
    "schema = [\"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"]\n",
    "\n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|department|sum(salary)|\n",
      "+----------+-----------+\n",
      "|Sales     |257000     |\n",
      "|Finance   |351000     |\n",
      "|Marketing |171000     |\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupBy and aggregate\n",
    "df.groupBy(\"department\").sum(\"salary\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx_count_distinct: 8\n"
     ]
    }
   ],
   "source": [
    "# approx_count_distinct\n",
    "print(\"approx_count_distinct: \" + \\\n",
    "      str(df.select(approx_count_distinct(\"salary\")).collect()[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg: 86555.55555555556\n"
     ]
    }
   ],
   "source": [
    "# avg (average)\n",
    "print(\"avg: \" + str(df.select(avg(\"salary\")).collect()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------+\n",
      "|collect_list(salary)                                           |\n",
      "+---------------------------------------------------------------+\n",
      "|[90000, 86000, 81000, 90000, 99000, 83000, 79000, 80000, 91000]|\n",
      "+---------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# collect_list\n",
    "df.select(collect_list(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------+\n",
      "|collect_set(salary)                                     |\n",
      "+--------------------------------------------------------+\n",
      "|[79000, 83000, 91000, 99000, 90000, 80000, 86000, 81000]|\n",
      "+--------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# collect_set\n",
    "df.select(collect_set(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|count(DISTINCT department, salary)|\n",
      "+----------------------------------+\n",
      "|9                                 |\n",
      "+----------------------------------+\n",
      "\n",
      "Distinct Count of Department & Salary: 9\n"
     ]
    }
   ],
   "source": [
    "# countDistinct\n",
    "df2 = df.select(countDistinct(\"department\", \"salary\"))\n",
    "df2.show(truncate=False)\n",
    "print(\"Distinct Count of Department & Salary: \"+str(df2.collect()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: Row(count(salary)=9)\n"
     ]
    }
   ],
   "source": [
    "# count function\n",
    "print(\"count: \"+str(df.select(count(\"salary\")).collect()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|first(salary)|\n",
      "+-------------+\n",
      "|90000        |\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first\n",
    "df.select(first(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first().salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|last(salary)|\n",
      "+------------+\n",
      "|91000       |\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# last\n",
    "df.select(last(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|kurtosis(salary)   |\n",
      "+-------------------+\n",
      "|-0.6275168662506321|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kurtosis\n",
    "df.select(kurtosis(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|max(salary)|\n",
      "+-----------+\n",
      "|99000      |\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# max\n",
    "df.select(max(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|min(salary)|\n",
      "+-----------+\n",
      "|79000      |\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# min\n",
    "df.select(min(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|avg(salary)      |\n",
      "+-----------------+\n",
      "|86555.55555555556|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mean\n",
    "df.select(mean(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|skewness(salary)  |\n",
      "+------------------+\n",
      "|0.5530468967432594|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# skewness\n",
    "df.select(skewness(\"salary\")).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------------+\n",
      "|stddev_samp(salary)|stddev_samp(salary)|stddev_pop(salary)|\n",
      "+-------------------+-------------------+------------------+\n",
      "|6540.472290116195  |6540.472290116195  |6166.416411338492 |\n",
      "+-------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stddev(), stddev_samp() and stddev_pop()\n",
    "df.select(stddev(\"salary\"), stddev_samp(\"salary\"), stddev_pop(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(salary)|\n",
      "+-----------+\n",
      "|779000     |\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sum\n",
    "df.select(sum(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|sum(DISTINCT salary)|\n",
      "+--------------------+\n",
      "|689000              |\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sumDistinct\n",
    "df.select(sumDistinct(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+\n",
      "|var_samp(salary)   |var_samp(salary)   |var_pop(salary)     |\n",
      "+-------------------+-------------------+--------------------+\n",
      "|4.277777777777778E7|4.277777777777778E7|3.8024691358024694E7|\n",
      "+-------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# variance(), var_samp(), var_pop()\n",
    "df.select(variance(\"salary\"),var_samp(\"salary\"),var_pop(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block displayed below contains an error. The code block should return the average of rows in column value grouped by unique storeId. Find the error.\n",
    "\n",
    "Code block:\n",
    "\n",
    "transactionsDf.agg(“storeId”).avg(“value”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|avg(salary)      |\n",
      "+-----------------+\n",
      "|86555.55555555556|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  agg should be replaced by groupBy.\n",
    "df.groupBy().avg(\"salary\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a DataFrame showing the mean value of column “value” of DataFrame transactionsDf, grouped by its column storeId?\n",
    ">\n",
    "- `transactionsDf.groupBy(col(storeId).avg())`\n",
    "- `transactionsDf.groupBy(\"storeId\").avg(col(\"value\"))`\n",
    "- `transactionsDf.groupBy(\"storeId\").agg(avg(\"value\"))`\n",
    "- `transactionsDf.groupBy(\"storeId\").agg(average(\"value\"))`\n",
    "- `transactionsDf.groupBy(\"value\").average()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "data = [(1, 3, 4, 25, 1, None, 1587915332),\n",
    "         (2, 6, 7, 2, 2, None, 1586815312),\n",
    "         (3, 3, None, 25, 3, None, 1585824821),\n",
    "         (4, None, None, 3, 2, None, 1583244275),\n",
    "         (5, None, None, None, 2, None, 1575285427),\n",
    "         (6, 3, 2, 25, 2, None, 1572733275)]\n",
    "\n",
    "schema = StructType([StructField('transactionId', IntegerType(), True),\n",
    "                     StructField('predError', IntegerType(), True),\n",
    "                     StructField('value', IntegerType(), True),\n",
    "                     StructField('storeId', IntegerType(), True),\n",
    "                     StructField('productId', IntegerType(), True),\n",
    "                     StructField('f', IntegerType(), True),\n",
    "                     StructField('transactionDate', LongType(), True)])\n",
    "\n",
    "transactionsDf = spark.createDataFrame(data=data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|storeId|avg(value)|\n",
      "+-------+----------+\n",
      "|   null|      null|\n",
      "|      3|      null|\n",
      "|     25|       3.0|\n",
      "|      2|       7.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.groupBy(\"storeId\").agg(avg(\"value\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|storeId|avg(value)|\n",
      "+-------+----------+\n",
      "|   null|      null|\n",
      "|      3|      null|\n",
      "|     25|       3.0|\n",
      "|      2|       7.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.groupBy(\"storeId\").avg(\"value\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NameError: name 'storeId' is not defined\n",
    "transactionsDf.groupBy(col(storeId).avg())\n",
    "\n",
    "# TypeError: Column is not iterable\n",
    "transactionsDf.groupBy(\"storeId\").avg(col(\"value\"))\n",
    "\n",
    "# NameError: name 'average' is not defined\n",
    "transactionsDf.groupBy(\"storeId\").agg(average(\"value\"))\n",
    "\n",
    "# AttributeError: 'GroupedData' object has no attribute 'average'\n",
    "transactionsDf.groupBy(\"value\").average()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given the following DataFrame.\n",
    ">\n",
    "- `+—+——+—-+`\n",
    "- `|Key| Name|Score|`\n",
    "- `+—+——+—-+`\n",
    "- `| 1| Apple| 0.76|`\n",
    "- `| 1|Orange| 0.98|`\n",
    "- `| 1|Banana| 0.24|`\n",
    "- `| 2| Apple| 0.11|`\n",
    "- `| 2|Banana| 0.99|`\n",
    "- `+—+——+—-+`\n",
    ">\n",
    "And you are asked to transform and generate the following output.\n",
    ">\n",
    "- `+—+———————————————–+`\n",
    "- `|Key|Collection |`\n",
    "- `+—+———————————————–+`\n",
    "- `|1 |[[Apple, 0.76], [Orange, 0.98], [Banana, 0.24]] |`\n",
    "- `|2 |[[Apple, 0.11], [Banana, 0.99]] |`\n",
    "- `+—+———————————————–+`\n",
    ">\n",
    "Choose the correct code to generate the above output.\n",
    "\n",
    "- `df.groupBy(\"Key\", \"Name\", \"Score\") .agg(collect_list(struct(\"Name\", \"Score\")).alias(\"Collection\")) .show(truncate=0)`\n",
    "- `df.groupBy(\"Key\") .agg(collect_list(struct(\"Name\", \"Score\")).alias(\"Collection\")) .show(truncate=0)`\n",
    "- `df.groupBy(\"Key\") .agg(struct(struct(\"Name\", \"Score\")).alias(\"Collection\")) .show(truncate=0)`\n",
    "- `df.groupBy(\"Key\") .agg(arrayt(struct(\"Name\", \"Score\")).alias(\"Collection\")) .show(truncate=0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Key: long (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Score: double (nullable = true)\n",
      "\n",
      "+---+------+-----+\n",
      "|Key|  Name|Score|\n",
      "+---+------+-----+\n",
      "|  1| Apple| 0.76|\n",
      "|  1|Orange| 0.98|\n",
      "|  1|Banana| 0.24|\n",
      "|  2| Apple| 0.11|\n",
      "|  2|Banana| 0.99|\n",
      "+---+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Apple', 0.76),\n",
    "        (1, 'Orange', 0.98),\n",
    "        (1, 'Banana', 0.24),\n",
    "        (2, 'Apple', 0.11),\n",
    "        (2, 'Banana', 0.99)]\n",
    "\n",
    "columns = [\"Key\", \"Name\", \"Score\"]\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+----------------+\n",
      "|Key|Name  |Score|Collection      |\n",
      "+---+------+-----+----------------+\n",
      "|2  |Apple |0.11 |[[Apple, 0.11]] |\n",
      "|2  |Banana|0.99 |[[Banana, 0.99]]|\n",
      "|1  |Apple |0.76 |[[Apple, 0.76]] |\n",
      "|1  |Orange|0.98 |[[Orange, 0.98]]|\n",
      "|1  |Banana|0.24 |[[Banana, 0.24]]|\n",
      "+---+------+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Key\", \"Name\", \"Score\").agg(collect_list(struct(\"Name\", \"Score\")).alias(\"Collection\")).show(truncate=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------------------+\n",
      "|Key|Collection                                     |\n",
      "+---+-----------------------------------------------+\n",
      "|1  |[[Apple, 0.76], [Orange, 0.98], [Banana, 0.24]]|\n",
      "|2  |[[Apple, 0.11], [Banana, 0.99]]                |\n",
      "+---+-----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Key\").agg(collect_list(struct(\"Name\", \"Score\")).alias(\"Collection\")).show(truncate=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnalysisException: expression '`Name`' is neither present in the group by, nor is it an aggregate function\n",
    "df.groupBy(\"Key\").agg(struct(struct(\"Name\", \"Score\")).alias(\"Collection\")).show(truncate=0)\n",
    "\n",
    "# NameError: name 'arrayt' is not defined\n",
    "df.groupBy(\"Key\").agg(arrayt(struct(\"Name\", \"Score\")).alias(\"Collection\")).show(truncate=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select all valid expressions to calculate the sum of Quantity for each InvoiceNo in the following DataFrame.\n",
    ">\n",
    "- `df.groupBy(\"InvoiceNo\").agg(\"sum(Quantity)\")`\n",
    "- `df.groupBy(\"InvoiceNo\").agg(sum(\"Quantity\"))`\n",
    "- `df.select(\"InvoiceNo\", expr(\"sum(Quantity)\"))`\n",
    "- `df.groupBy(\"InvoiceNo\").select(\"InvoiceNo\", expr(\"sum(Quantity)\"))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [('536365','85123A', '6'),\n",
    "             ('536365','85123B', '5'),\n",
    "             ('536366','85123C', '2'),\n",
    "             ('536366','85123D', '6'),\n",
    "             ('536366','85123E', '8')]\n",
    "             \n",
    "df = spark.createDataFrame(data_list).toDF('InvoiceNo', 'StockCode', 'Quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|InvoiceNo|sum(Quantity)|\n",
      "+---------+-------------+\n",
      "|   536365|         11.0|\n",
      "|   536366|         16.0|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"InvoiceNo\").agg(sum(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "all exprs should be Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fbdc191b09c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"InvoiceNo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sum(Quantity)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/group.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# Columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexprs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all exprs should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             jdf = self._jgd.agg(exprs[0]._jc,\n\u001b[1;32m    119\u001b[0m                                 _to_seq(self.sql_ctx._sc, [c._jc for c in exprs[1:]]))\n",
      "\u001b[0;31mAssertionError\u001b[0m: all exprs should be Column"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"InvoiceNo\").agg(\"sum(Quantity)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6ad6cad6e86b8f8ebaedbe94ebc31d728d6c0d8223a99e9449734cfa4d7995"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
