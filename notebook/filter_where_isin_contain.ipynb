{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILTER() + WHERE() + ISIN() + CONTAIN() + WHEN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"example-filter-isin\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|Finance  |10     |\n",
      "|Marketing|20     |\n",
      "|Sales    |30     |\n",
      "|IT       |40     |\n",
      "|X        |40     |\n",
      "|Y        |40     |\n",
      "|Z        |40     |\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dept = [(\"Finance\",10), (\"Marketing\",20), (\"Sales\",30), (\"IT\",40), (\"X\",40), (\"Y\",40), (\"Z\",40)]\n",
    "deptColumns = [\"dept_name\", \"dept_id\"]\n",
    "\n",
    "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
    "deptDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Undefined function: 'col'. This function is neither a registered temporary function nor a permanent function registered in the database 'default'.; line 1 pos 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5fe81a0d00c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  The argument to the where method cannot be a string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdeptDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col(dept_id) >= 30\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \"\"\"\n\u001b[1;32m   1458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Undefined function: 'col'. This function is neither a registered temporary function nor a permanent function registered in the database 'default'.; line 1 pos 0"
     ]
    }
   ],
   "source": [
    "#  The argument to the where method cannot be a string.\n",
    "deptDF.where(\"col(dept_id) >= 30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deptDF.where(col('dept_id') >= 30).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block displayed below contains an error. The code block should return a DataFrame where all entries in column supplier contain the letter combination et in this order. Find the error.\n",
    ">\n",
    "Code block:\n",
    ">\n",
    "- `itemsDf.filter(column(‘supplier’).isin(‘et’))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- itemId: long (nullable = true)\n",
      " |-- itemName: string (nullable = true)\n",
      " |-- supplier: string (nullable = true)\n",
      "\n",
      "+------+--------------------+-------------------+\n",
      "|itemId|            itemName|           supplier|\n",
      "+------+--------------------+-------------------+\n",
      "|     1|Thick Coat for Wa...|Sports Company Inc.|\n",
      "|     2|Elegant Outdoors ...|              YetiX|\n",
      "|     3|   Outdoors Backpack|Sports Company Inc.|\n",
      "+------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Thick Coat for Walking in the Snow', 'Sports Company Inc.'),\n",
    "        (2, 'Elegant Outdoors Summer Dress', 'YetiX'),\n",
    "        (3, 'Outdoors Backpack', 'Sports Company Inc.')]\n",
    "\n",
    "columns = [\"itemId\", \"itemName\", \"supplier\"]\n",
    "\n",
    "itemsDf = spark.createDataFrame(data=data, schema=columns)\n",
    "\n",
    "itemsDf.printSchema()\n",
    "itemsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-------------------+\n",
      "|itemId|            itemName|           supplier|\n",
      "+------+--------------------+-------------------+\n",
      "|     1|Thick Coat for Wa...|Sports Company Inc.|\n",
      "|     3|   Outdoors Backpack|Sports Company Inc.|\n",
      "+------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "itemsDf[itemsDf.supplier.isin(\"Sports Company Inc.\")].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-------------------+\n",
      "|itemId|            itemName|           supplier|\n",
      "+------+--------------------+-------------------+\n",
      "|     1|Thick Coat for Wa...|Sports Company Inc.|\n",
      "|     3|   Outdoors Backpack|Sports Company Inc.|\n",
      "+------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "itemsDf.filter(col(\"supplier\").contains(\"Company\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a new DataFrame with only columns predError and values of every second row of DataFrame transactionsDf?\n",
    ">\n",
    "Entire DataFrame transactionsDf:\n",
    ">\n",
    "- `+————-+———+—–+——-+———+—-+`\n",
    "- `|transactionId|predError|value|storeId|productId| f|`\n",
    "- `+————-+———+—–+——-+———+—-+`\n",
    "- `| 1| 3| 4| 25| 1|null|`\n",
    "- `| 2| 6| 7| 2| 2|null|`\n",
    "- `| 3| 3| null| 25| 3|null|`\n",
    "- `| 4| null| null| 3| 2|null|`\n",
    "- `| 5| null| null| null| 2|null|`\n",
    "- `| 6| 3| 2| 25| 2|null|`\n",
    "- `+————-+———+—–+——-+———+—-+`\n",
    ">\n",
    "- `transactionsDf.filter(col(\"transactionId\").isin([3,4,6])).select([predError, value])`\n",
    "- `transactionsDf.select(col(\"transactionId\").isin([3,4,6]), \"predError\", \"value\")`\n",
    "- `transactionsDf.filter(\"transactionId\" % 2 == 0).select(\"predError\", \"value\")`\n",
    "- `transactionsDf.filter(col(\"transactionId\") % 2 == 0).select(\"predError\", \"value\")`\n",
    "- `transactionsDf.createOrReplaceTempView(\"transactionsDf\")`\n",
    "- `spark.sql(\"FROM transactionsDf SELECT predError, value WHERE transactionId % 2 = 0\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+\n",
      "|transactionId|predError|value|storeId|productId|   f|\n",
      "+-------------+---------+-----+-------+---------+----+\n",
      "|            1|        3|    4|     25|        1|null|\n",
      "|            2|        6|    7|      2|        2|null|\n",
      "|            3|        3| null|     25|        3|null|\n",
      "|            4|     null| null|      3|        2|null|\n",
      "|            5|     null| null|   null|        2|null|\n",
      "|            6|        3|    2|     25|        2|null|\n",
      "+-------------+---------+-----+-------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "data = [(1, 3, 4, 25, 1, None),\n",
    "        (2, 6, 7, 2, 2, None),\n",
    "        (3, 3, None, 25, 3, None),\n",
    "        (4, None, None, 3, 2, None),\n",
    "        (5, None, None, None, 2, None),\n",
    "        (6, 3, 2, 25, 2, None)]\n",
    "\n",
    "schema = StructType([StructField('transactionId', IntegerType(), True),\n",
    "                     StructField('predError', IntegerType(), True),\n",
    "                     StructField('value', IntegerType(), True),\n",
    "                     StructField('storeId', IntegerType(), True),\n",
    "                     StructField('productId', IntegerType(), True),\n",
    "                     StructField('f', IntegerType(), True)])\n",
    "\n",
    "transactionsDf = spark.createDataFrame(data=data, schema=schema)\n",
    "transactionsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------+-----+\n",
      "|(transactionId IN (3, 4, 6))|predError|value|\n",
      "+----------------------------+---------+-----+\n",
      "|                       false|        3|    4|\n",
      "|                       false|        6|    7|\n",
      "|                        true|        3| null|\n",
      "|                        true|     null| null|\n",
      "|                       false|     null| null|\n",
      "|                        true|        3|    2|\n",
      "+----------------------------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.select(col(\"transactionId\").isin([3,4,6]), \"predError\", \"value\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|predError|value|\n",
      "+---------+-----+\n",
      "|        6|    7|\n",
      "|     null| null|\n",
      "|        3|    2|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.filter(col(\"transactionId\") % 2 == 0).select(\"predError\", \"value\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|predError|value|\n",
      "+---------+-----+\n",
      "|        6|    7|\n",
      "|     null| null|\n",
      "|        3|    2|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"FROM transactionsDf SELECT predError, value WHERE transactionId % 2 = 0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NameError: name 'predError' is not defined\n",
    "# transactionsDf.filter(col(\"transactionId\").isin([3,4,6])).select([predError, value])\n",
    "\n",
    "# TypeError: not all arguments converted during string formatting\n",
    "# transactionsDf.filter(\"transactionId\" % 2 == 0).select(\"predError\", \"value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+------------+\n",
      "|transactionId|predError|value|storeId|productId|   f|productGroup|\n",
      "+-------------+---------+-----+-------+---------+----+------------+\n",
      "|            1|        3|    4|     25|        1|null|      Grupo1|\n",
      "|            2|        6|    7|      2|        2|null|      Grupo2|\n",
      "|            3|        3| null|     25|        3|null|      Grupo3|\n",
      "|            4|     null| null|      3|        2|null|      Grupo2|\n",
      "|            5|     null| null|   null|        2|null|      Grupo2|\n",
      "|            6|        3|    2|     25|        2|null|      Grupo2|\n",
      "+-------------+---------+-----+-------+---------+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cond1 = col(\"productId\").isin(1)\n",
    "cond2 = col(\"productId\").isin(2)\n",
    "cond3 = col(\"productId\").isin(3)\n",
    "\n",
    "transactionsDf.withColumn(\"productGroup\", when(cond1, \"Grupo1\")\n",
    "\t\t\t\t\t\t\t\t         .when(cond2, \"Grupo2\")\n",
    "\t\t\t\t\t\t\t\t         .when(cond3, \"Grupo3\")\n",
    "\t\t\t\t\t\t\t\t         .otherwise(\"Grupo4\")) \\\n",
    "\t\t\t\t\t\t\t\t  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----------+\n",
      "| id|Idade|Idade_Grupo|\n",
      "+---+-----+-----------+\n",
      "|  1|   13|     Grupo2|\n",
      "|  2|   23|     Grupo4|\n",
      "|  3|   10|     Grupo1|\n",
      "|  4|   17|     Grupo3|\n",
      "|  5|   18|     Grupo3|\n",
      "|  6|   21|     Grupo4|\n",
      "|  7|    9|     Grupo4|\n",
      "|  8|   26|     Grupo4|\n",
      "|  9|   28|     Grupo4|\n",
      "+---+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (1, 13), \n",
    "        (2, 23),\n",
    "\t\t(3, 10),\n",
    "\t\t(4, 17),\n",
    "\t\t(5, 18),\n",
    "\t\t(6, 21),\n",
    "\t\t(7, 9),\n",
    "\t\t(8, 26),\n",
    "\t\t(9, 28),\n",
    "\t\t\n",
    "    ], [\"id\", \"Idade\"])\n",
    "\n",
    "cond1 = col(\"Idade\").isin(10, 11, 12)\n",
    "cond2 = col(\"Idade\").isin(13, 14, 15)\n",
    "cond3 = col(\"Idade\").isin(16, 17, 18)\n",
    "\n",
    "df.withColumn(\"Idade_Grupo\", when(cond1, \"Grupo1\")\n",
    "                            .when(cond2, \"Grupo2\")\n",
    "                            .when(cond3, \"Grupo3\")\n",
    "                            .otherwise(\"Grupo4\")) \\\n",
    "\t\t\t .show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a one-column DataFrame of all values in column supplier of DataFrame itemsDf that do not contain the letter X? In the DataFrame, every value should only be listed once.\n",
    ">\n",
    "Sample of DataFrame itemsDf:\n",
    ">\n",
    "- `+——+——————–+——————–+——————-+`\n",
    "- `|itemId| itemName| attributes| supplier|`\n",
    "- `+——+——————–+——————–+——————-+`\n",
    "- `| 1|Thick Coat for Wa…|[blue, winter, cozy]|Sports Company Inc.|`\n",
    "- `| 2|Elegant Outdoors …|[red, summer, fre…| YetiX|`\n",
    "- `| 3| Outdoors Backpack|[green, summer, t…|Sports Company Inc.|`\n",
    "- `+——+——————–+——————–+——————-+`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- itemId: long (nullable = true)\n",
      " |-- itemName: string (nullable = true)\n",
      " |-- attributes: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- supplier: string (nullable = true)\n",
      "\n",
      "+------+--------------------+--------------------+-------------------+\n",
      "|itemId|            itemName|          attributes|           supplier|\n",
      "+------+--------------------+--------------------+-------------------+\n",
      "|     1|Thick Coat for Wa...|[blue, winter, cozy]|Sports Company Inc.|\n",
      "|     2|Elegant Outdoors ...|       [red, summer]|              YetiX|\n",
      "|     3|   Outdoors Backpack|     [green, summer]|Sports Company Inc.|\n",
      "+------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Thick Coat for Walking in the Snow', ['blue', 'winter', 'cozy'], 'Sports Company Inc.'),\n",
    "        (2, 'Elegant Outdoors Summer Dress', ['red', 'summer'], 'YetiX'),\n",
    "        (3, 'Outdoors Backpack', ['green', 'summer'], 'Sports Company Inc.')]\n",
    "\n",
    "columns = [\"itemId\", \"itemName\", \"attributes\", \"supplier\"]\n",
    "\n",
    "itemsDf = spark.createDataFrame(data=data, schema=columns)\n",
    "\n",
    "itemsDf.printSchema()\n",
    "itemsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|(NOT contains(supplier, X))|\n",
      "+---------------------------+\n",
      "|                       true|\n",
      "|                      false|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "itemsDf.select(~col('supplier').contains('X')).distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|           supplier|\n",
      "+-------------------+\n",
      "|Sports Company Inc.|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "itemsDf.filter(~col('supplier').contains('X')).select('supplier').distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NameError: name 'supplier' is not defined\n",
    "itemsDf.filter(col(supplier).not_contains('X')).select(supplier).distinct().show()\n",
    "\n",
    "# ValueError: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.\n",
    "itemsDf.filter(not(col('supplier').contains('X'))).select('supplier').unique().show()\n",
    "\n",
    "# SyntaxError: invalid syntax !\n",
    "itemsDf.filter(!col('supplier').contains('X')).select(col('supplier')).unique().show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6ad6cad6e86b8f8ebaedbe94ebc31d728d6c0d8223a99e9449734cfa4d7995"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
