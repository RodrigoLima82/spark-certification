{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILTER() + WHERE() + ISIN() + CONTAIN() + WHEN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"example-filter-isin\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|Finance  |10     |\n",
      "|Marketing|20     |\n",
      "|Sales    |30     |\n",
      "|IT       |40     |\n",
      "|X        |40     |\n",
      "|Y        |40     |\n",
      "|Z        |40     |\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dept = [(\"Finance\",10), (\"Marketing\",20), (\"Sales\",30), (\"IT\",40), (\"X\",40), (\"Y\",40), (\"Z\",40)]\n",
    "deptColumns = [\"dept_name\", \"dept_id\"]\n",
    "\n",
    "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
    "deptDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Undefined function: 'col'. This function is neither a registered temporary function nor a permanent function registered in the database 'default'.; line 1 pos 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5fe81a0d00c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  The argument to the where method cannot be a string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdeptDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col(dept_id) >= 30\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \"\"\"\n\u001b[1;32m   1458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Undefined function: 'col'. This function is neither a registered temporary function nor a permanent function registered in the database 'default'.; line 1 pos 0"
     ]
    }
   ],
   "source": [
    "#  The argument to the where method cannot be a string.\n",
    "deptDF.where(\"col(dept_id) >= 30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|    Sales|     30|\n",
      "|       IT|     40|\n",
      "|        X|     40|\n",
      "|        Y|     40|\n",
      "|        Z|     40|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deptDF.where(col('dept_id') >= 30).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block displayed below contains an error. The code block should return a DataFrame where all entries in column supplier contain the letter combination et in this order. Find the error.\n",
    ">\n",
    "Code block:\n",
    ">\n",
    "- `itemsDf.filter(column(‘supplier’).isin(‘et’))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- itemId: long (nullable = true)\n",
      " |-- itemName: string (nullable = true)\n",
      " |-- supplier: string (nullable = true)\n",
      "\n",
      "+------+--------------------+-------------------+\n",
      "|itemId|            itemName|           supplier|\n",
      "+------+--------------------+-------------------+\n",
      "|     1|Thick Coat for Wa...|Sports Company Inc.|\n",
      "|     2|Elegant Outdoors ...|              YetiX|\n",
      "|     3|   Outdoors Backpack|Sports Company Inc.|\n",
      "+------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Thick Coat for Walking in the Snow', 'Sports Company Inc.'),\n",
    "        (2, 'Elegant Outdoors Summer Dress', 'YetiX'),\n",
    "        (3, 'Outdoors Backpack', 'Sports Company Inc.')]\n",
    "\n",
    "columns = [\"itemId\", \"itemName\", \"supplier\"]\n",
    "\n",
    "itemsDf = spark.createDataFrame(data=data, schema=columns)\n",
    "\n",
    "itemsDf.printSchema()\n",
    "itemsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-------------------+\n",
      "|itemId|            itemName|           supplier|\n",
      "+------+--------------------+-------------------+\n",
      "|     1|Thick Coat for Wa...|Sports Company Inc.|\n",
      "|     3|   Outdoors Backpack|Sports Company Inc.|\n",
      "+------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "itemsDf[itemsDf.supplier.isin(\"Sports Company Inc.\")].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-------------------+\n",
      "|itemId|            itemName|           supplier|\n",
      "+------+--------------------+-------------------+\n",
      "|     1|Thick Coat for Wa...|Sports Company Inc.|\n",
      "|     3|   Outdoors Backpack|Sports Company Inc.|\n",
      "+------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "itemsDf.filter(col(\"supplier\").contains(\"Company\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a new DataFrame with only columns predError and values of every second row of DataFrame transactionsDf?\n",
    ">\n",
    "Entire DataFrame transactionsDf:\n",
    ">\n",
    "- `+————-+———+—–+——-+———+—-+`\n",
    "- `|transactionId|predError|value|storeId|productId| f|`\n",
    "- `+————-+———+—–+——-+———+—-+`\n",
    "- `| 1| 3| 4| 25| 1|null|`\n",
    "- `| 2| 6| 7| 2| 2|null|`\n",
    "- `| 3| 3| null| 25| 3|null|`\n",
    "- `| 4| null| null| 3| 2|null|`\n",
    "- `| 5| null| null| null| 2|null|`\n",
    "- `| 6| 3| 2| 25| 2|null|`\n",
    "- `+————-+———+—–+——-+———+—-+`\n",
    ">\n",
    "- `transactionsDf.filter(col(\"transactionId\").isin([3,4,6])).select([predError, value])`\n",
    "- `transactionsDf.select(col(\"transactionId\").isin([3,4,6]), \"predError\", \"value\")`\n",
    "- `transactionsDf.filter(\"transactionId\" % 2 == 0).select(\"predError\", \"value\")`\n",
    "- `transactionsDf.filter(col(\"transactionId\") % 2 == 0).select(\"predError\", \"value\")`\n",
    "- `transactionsDf.createOrReplaceTempView(\"transactionsDf\")`\n",
    "- `spark.sql(\"FROM transactionsDf SELECT predError, value WHERE transactionId % 2 = 0\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+\n",
      "|transactionId|predError|value|storeId|productId|   f|\n",
      "+-------------+---------+-----+-------+---------+----+\n",
      "|            1|        3|    4|     25|        1|null|\n",
      "|            2|        6|    7|      2|        2|null|\n",
      "|            3|        3| null|     25|        3|null|\n",
      "|            4|     null| null|      3|        2|null|\n",
      "|            5|     null| null|   null|        2|null|\n",
      "|            6|        3|    2|     25|        2|null|\n",
      "+-------------+---------+-----+-------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "data = [(1, 3, 4, 25, 1, None),\n",
    "        (2, 6, 7, 2, 2, None),\n",
    "        (3, 3, None, 25, 3, None),\n",
    "        (4, None, None, 3, 2, None),\n",
    "        (5, None, None, None, 2, None),\n",
    "        (6, 3, 2, 25, 2, None)]\n",
    "\n",
    "schema = StructType([StructField('transactionId', IntegerType(), True),\n",
    "                     StructField('predError', IntegerType(), True),\n",
    "                     StructField('value', IntegerType(), True),\n",
    "                     StructField('storeId', IntegerType(), True),\n",
    "                     StructField('productId', IntegerType(), True),\n",
    "                     StructField('f', IntegerType(), True)])\n",
    "\n",
    "transactionsDf = spark.createDataFrame(data=data, schema=schema)\n",
    "transactionsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+\n",
      "|transactionId|predError|value|storeId|productId|   f|\n",
      "+-------------+---------+-----+-------+---------+----+\n",
      "|            3|        3| null|     25|        3|null|\n",
      "+-------------+---------+-----+-------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.filter((col(\"productId\")==3) | (col(\"productId\")<1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-fd3de26aeb47>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-fd3de26aeb47>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    transactionsDf.where(\"productId\"=3).or(\"productId\"<1))\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# NameError: name 'productId' is not defined\n",
    "transactionsDf.filter(productId==3 or productId<1)\n",
    "\n",
    "# ValueError: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not'\n",
    "transactionsDf.filter((col(\"productId\")==3) or (col(\"productId\")<1))\n",
    "\n",
    "# Py4JError: An error occurred while calling o43.or. \n",
    "# Trace: py4j.Py4JException: Method or([class java.lang.Integer]) does not exist\n",
    "transactionsDf.filter(col(\"productId\")==3 | col(\"productId\")<1)\n",
    "\n",
    "# SyntaxError: invalid syntax \"or\"\n",
    "transactionsDf.where(\"productId\"=3).or(\"productId\"<1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------+-----+\n",
      "|(transactionId IN (3, 4, 6))|predError|value|\n",
      "+----------------------------+---------+-----+\n",
      "|                       false|        3|    4|\n",
      "|                       false|        6|    7|\n",
      "|                        true|        3| null|\n",
      "|                        true|     null| null|\n",
      "|                       false|     null| null|\n",
      "|                        true|        3|    2|\n",
      "+----------------------------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.select(col(\"transactionId\").isin([3,4,6]), \"predError\", \"value\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|predError|value|\n",
      "+---------+-----+\n",
      "|        6|    7|\n",
      "|     null| null|\n",
      "|        3|    2|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.filter(col(\"transactionId\") % 2 == 0).select(\"predError\", \"value\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view not found: transactionsDf; line 1 pos 5;\n'Project ['predError, 'value]\n+- 'Filter (('transactionId % 2) = 0)\n   +- 'UnresolvedRelation [transactionsDf]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7242d2522032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FROM transactionsDf SELECT predError, value WHERE transactionId % 2 = 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \"\"\"\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: transactionsDf; line 1 pos 5;\n'Project ['predError, 'value]\n+- 'Filter (('transactionId % 2) = 0)\n   +- 'UnresolvedRelation [transactionsDf]\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"FROM transactionsDf SELECT predError, value WHERE transactionId % 2 = 0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NameError: name 'predError' is not defined\n",
    "# transactionsDf.filter(col(\"transactionId\").isin([3,4,6])).select([predError, value])\n",
    "\n",
    "# TypeError: not all arguments converted during string formatting\n",
    "# transactionsDf.filter(\"transactionId\" % 2 == 0).select(\"predError\", \"value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+------------+\n",
      "|transactionId|predError|value|storeId|productId|   f|productGroup|\n",
      "+-------------+---------+-----+-------+---------+----+------------+\n",
      "|            1|        3|    4|     25|        1|null|      Grupo1|\n",
      "|            2|        6|    7|      2|        2|null|      Grupo2|\n",
      "|            3|        3| null|     25|        3|null|      Grupo3|\n",
      "|            4|     null| null|      3|        2|null|      Grupo2|\n",
      "|            5|     null| null|   null|        2|null|      Grupo2|\n",
      "|            6|        3|    2|     25|        2|null|      Grupo2|\n",
      "+-------------+---------+-----+-------+---------+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cond1 = col(\"productId\").isin(1)\n",
    "cond2 = col(\"productId\").isin(2)\n",
    "cond3 = col(\"productId\").isin(3)\n",
    "\n",
    "transactionsDf.withColumn(\"productGroup\", when(cond1, \"Grupo1\")\n",
    "\t\t\t\t\t\t\t\t         .when(cond2, \"Grupo2\")\n",
    "\t\t\t\t\t\t\t\t         .when(cond3, \"Grupo3\")\n",
    "\t\t\t\t\t\t\t\t         .otherwise(\"Grupo4\")) \\\n",
    "\t\t\t\t\t\t\t\t  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----------+\n",
      "| id|Idade|Idade_Grupo|\n",
      "+---+-----+-----------+\n",
      "|  1|   13|     Grupo2|\n",
      "|  2|   23|     Grupo4|\n",
      "|  3|   10|     Grupo1|\n",
      "|  4|   17|     Grupo3|\n",
      "|  5|   18|     Grupo3|\n",
      "|  6|   21|     Grupo4|\n",
      "|  7|    9|     Grupo4|\n",
      "|  8|   26|     Grupo4|\n",
      "|  9|   28|     Grupo4|\n",
      "+---+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (1, 13), \n",
    "        (2, 23),\n",
    "\t\t(3, 10),\n",
    "\t\t(4, 17),\n",
    "\t\t(5, 18),\n",
    "\t\t(6, 21),\n",
    "\t\t(7, 9),\n",
    "\t\t(8, 26),\n",
    "\t\t(9, 28),\n",
    "\t\t\n",
    "    ], [\"id\", \"Idade\"])\n",
    "\n",
    "cond1 = col(\"Idade\").isin(10, 11, 12)\n",
    "cond2 = col(\"Idade\").isin(13, 14, 15)\n",
    "cond3 = col(\"Idade\").isin(16, 17, 18)\n",
    "\n",
    "df.withColumn(\"Idade_Grupo\", when(cond1, \"Grupo1\")\n",
    "                            .when(cond2, \"Grupo2\")\n",
    "                            .when(cond3, \"Grupo3\")\n",
    "                            .otherwise(\"Grupo4\")) \\\n",
    "\t\t\t .show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a one-column DataFrame of all values in column supplier of DataFrame itemsDf that do not contain the letter X? In the DataFrame, every value should only be listed once.\n",
    ">\n",
    "Sample of DataFrame itemsDf:\n",
    ">\n",
    "- `+——+——————–+——————–+——————-+`\n",
    "- `|itemId| itemName| attributes| supplier|`\n",
    "- `+——+——————–+——————–+——————-+`\n",
    "- `| 1|Thick Coat for Wa…|[blue, winter, cozy]|Sports Company Inc.|`\n",
    "- `| 2|Elegant Outdoors …|[red, summer, fre…| YetiX|`\n",
    "- `| 3| Outdoors Backpack|[green, summer, t…|Sports Company Inc.|`\n",
    "- `+——+——————–+——————–+——————-+`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- itemId: long (nullable = true)\n",
      " |-- itemName: string (nullable = true)\n",
      " |-- attributes: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- supplier: string (nullable = true)\n",
      "\n",
      "+------+--------------------+--------------------+-------------------+\n",
      "|itemId|            itemName|          attributes|           supplier|\n",
      "+------+--------------------+--------------------+-------------------+\n",
      "|     1|Thick Coat for Wa...|[blue, winter, cozy]|Sports Company Inc.|\n",
      "|     2|Elegant Outdoors ...|       [red, summer]|              YetiX|\n",
      "|     3|   Outdoors Backpack|     [green, summer]|Sports Company Inc.|\n",
      "+------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Thick Coat for Walking in the Snow', ['blue', 'winter', 'cozy'], 'Sports Company Inc.'),\n",
    "        (2, 'Elegant Outdoors Summer Dress', ['red', 'summer'], 'YetiX'),\n",
    "        (3, 'Outdoors Backpack', ['green', 'summer'], 'Sports Company Inc.')]\n",
    "\n",
    "columns = [\"itemId\", \"itemName\", \"attributes\", \"supplier\"]\n",
    "\n",
    "itemsDf = spark.createDataFrame(data=data, schema=columns)\n",
    "\n",
    "itemsDf.printSchema()\n",
    "itemsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|(NOT contains(supplier, X))|\n",
      "+---------------------------+\n",
      "|                       true|\n",
      "|                      false|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "itemsDf.select(~col('supplier').contains('X')).distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|           supplier|\n",
      "+-------------------+\n",
      "|Sports Company Inc.|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "itemsDf.filter(~col('supplier').contains('X')).select('supplier').distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-a02107b1abe3>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-a02107b1abe3>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    itemsDf.filter(!col('supplier').contains('X')).select(col('supplier')).unique().show()\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# NameError: name 'supplier' is not defined\n",
    "itemsDf.filter(col(supplier).not_contains('X')).select(supplier).distinct().show()\n",
    "\n",
    "# ValueError: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.\n",
    "itemsDf.filter(not(col('supplier').contains('X'))).select('supplier').unique().show()\n",
    "\n",
    "# SyntaxError: invalid syntax !\n",
    "itemsDf.filter(!col('supplier').contains('X')).select(col('supplier')).unique().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------+-----+\n",
      "|(transactionId IN (3, 4, 6))|predError|value|\n",
      "+----------------------------+---------+-----+\n",
      "|                       false|        3|    4|\n",
      "|                       false|        6|    7|\n",
      "|                        true|        3| null|\n",
      "|                        true|     null| null|\n",
      "|                       false|     null| null|\n",
      "|                        true|        3|    2|\n",
      "+----------------------------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.select(col(\"transactionId\").isin([3,4,6]), \"predError\", \"value\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|predError|value|\n",
      "+---------+-----+\n",
      "|        6|    7|\n",
      "|     null| null|\n",
      "|        3|    2|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.filter(col(\"transactionId\") % 2 == 0).select(\"predError\", \"value\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view not found: transactionsDf; line 1 pos 5;\n'Project ['predError, 'value]\n+- 'Filter (('transactionId % 2) = 0)\n   +- 'UnresolvedRelation [transactionsDf]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7242d2522032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FROM transactionsDf SELECT predError, value WHERE transactionId % 2 = 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \"\"\"\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: transactionsDf; line 1 pos 5;\n'Project ['predError, 'value]\n+- 'Filter (('transactionId % 2) = 0)\n   +- 'UnresolvedRelation [transactionsDf]\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"FROM transactionsDf SELECT predError, value WHERE transactionId % 2 = 0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NameError: name 'predError' is not defined\n",
    "# transactionsDf.filter(col(\"transactionId\").isin([3,4,6])).select([predError, value])\n",
    "\n",
    "# TypeError: not all arguments converted during string formatting\n",
    "# transactionsDf.filter(\"transactionId\" % 2 == 0).select(\"predError\", \"value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+------------+\n",
      "|transactionId|predError|value|storeId|productId|   f|productGroup|\n",
      "+-------------+---------+-----+-------+---------+----+------------+\n",
      "|            1|        3|    4|     25|        1|null|      Grupo1|\n",
      "|            2|        6|    7|      2|        2|null|      Grupo2|\n",
      "|            3|        3| null|     25|        3|null|      Grupo3|\n",
      "|            4|     null| null|      3|        2|null|      Grupo2|\n",
      "|            5|     null| null|   null|        2|null|      Grupo2|\n",
      "|            6|        3|    2|     25|        2|null|      Grupo2|\n",
      "+-------------+---------+-----+-------+---------+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cond1 = col(\"productId\").isin(1)\n",
    "cond2 = col(\"productId\").isin(2)\n",
    "cond3 = col(\"productId\").isin(3)\n",
    "\n",
    "transactionsDf.withColumn(\"productGroup\", when(cond1, \"Grupo1\")\n",
    "\t\t\t\t\t\t\t\t         .when(cond2, \"Grupo2\")\n",
    "\t\t\t\t\t\t\t\t         .when(cond3, \"Grupo3\")\n",
    "\t\t\t\t\t\t\t\t         .otherwise(\"Grupo4\")) \\\n",
    "\t\t\t\t\t\t\t\t  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----------+\n",
      "| id|Idade|Idade_Grupo|\n",
      "+---+-----+-----------+\n",
      "|  1|   13|     Grupo2|\n",
      "|  2|   23|     Grupo4|\n",
      "|  3|   10|     Grupo1|\n",
      "|  4|   17|     Grupo3|\n",
      "|  5|   18|     Grupo3|\n",
      "|  6|   21|     Grupo4|\n",
      "|  7|    9|     Grupo4|\n",
      "|  8|   26|     Grupo4|\n",
      "|  9|   28|     Grupo4|\n",
      "+---+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (1, 13), \n",
    "        (2, 23),\n",
    "\t\t(3, 10),\n",
    "\t\t(4, 17),\n",
    "\t\t(5, 18),\n",
    "\t\t(6, 21),\n",
    "\t\t(7, 9),\n",
    "\t\t(8, 26),\n",
    "\t\t(9, 28),\n",
    "\t\t\n",
    "    ], [\"id\", \"Idade\"])\n",
    "\n",
    "cond1 = col(\"Idade\").isin(10, 11, 12)\n",
    "cond2 = col(\"Idade\").isin(13, 14, 15)\n",
    "cond3 = col(\"Idade\").isin(16, 17, 18)\n",
    "\n",
    "df.withColumn(\"Idade_Grupo\", when(cond1, \"Grupo1\")\n",
    "                            .when(cond2, \"Grupo2\")\n",
    "                            .when(cond3, \"Grupo3\")\n",
    "                            .otherwise(\"Grupo4\")) \\\n",
    "\t\t\t .show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a one-column DataFrame of all values in column supplier of DataFrame itemsDf that do not contain the letter X? In the DataFrame, every value should only be listed once.\n",
    ">\n",
    "Sample of DataFrame itemsDf:\n",
    ">\n",
    "- `+——+——————–+——————–+——————-+`\n",
    "- `|itemId| itemName| attributes| supplier|`\n",
    "- `+——+——————–+——————–+——————-+`\n",
    "- `| 1|Thick Coat for Wa…|[blue, winter, cozy]|Sports Company Inc.|`\n",
    "- `| 2|Elegant Outdoors …|[red, summer, fre…| YetiX|`\n",
    "- `| 3| Outdoors Backpack|[green, summer, t…|Sports Company Inc.|`\n",
    "- `+——+——————–+——————–+——————-+`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- itemId: long (nullable = true)\n",
      " |-- itemName: string (nullable = true)\n",
      " |-- attributes: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- supplier: string (nullable = true)\n",
      "\n",
      "+------+--------------------+--------------------+-------------------+\n",
      "|itemId|            itemName|          attributes|           supplier|\n",
      "+------+--------------------+--------------------+-------------------+\n",
      "|     1|Thick Coat for Wa...|[blue, winter, cozy]|Sports Company Inc.|\n",
      "|     2|Elegant Outdoors ...|       [red, summer]|              YetiX|\n",
      "|     3|   Outdoors Backpack|     [green, summer]|Sports Company Inc.|\n",
      "+------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, 'Thick Coat for Walking in the Snow', ['blue', 'winter', 'cozy'], 'Sports Company Inc.'),\n",
    "        (2, 'Elegant Outdoors Summer Dress', ['red', 'summer'], 'YetiX'),\n",
    "        (3, 'Outdoors Backpack', ['green', 'summer'], 'Sports Company Inc.')]\n",
    "\n",
    "columns = [\"itemId\", \"itemName\", \"attributes\", \"supplier\"]\n",
    "\n",
    "itemsDf = spark.createDataFrame(data=data, schema=columns)\n",
    "\n",
    "itemsDf.printSchema()\n",
    "itemsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|(NOT contains(supplier, X))|\n",
      "+---------------------------+\n",
      "|                       true|\n",
      "|                      false|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "itemsDf.select(~col('supplier').contains('X')).distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|           supplier|\n",
      "+-------------------+\n",
      "|Sports Company Inc.|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "itemsDf.filter(~col('supplier').contains('X')).select('supplier').distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-a02107b1abe3>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-a02107b1abe3>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    itemsDf.filter(!col('supplier').contains('X')).select(col('supplier')).unique().show()\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# NameError: name 'supplier' is not defined\n",
    "itemsDf.filter(col(supplier).not_contains('X')).select(supplier).distinct().show()\n",
    "\n",
    "# ValueError: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.\n",
    "itemsDf.filter(not(col('supplier').contains('X'))).select('supplier').unique().show()\n",
    "\n",
    "# SyntaxError: invalid syntax !\n",
    "itemsDf.filter(!col('supplier').contains('X')).select(col('supplier')).unique().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a single row from DataFrame transactionsDf?\n",
    ">\n",
    "- `transactionsDf.where(col(\"storeId\").between(3,25))`\n",
    "- `transactionsDf.filter((col(\"storeId\")!=25) | (col(\"productId\")==2))`\n",
    "- `transactionsDf.filter(col(\"storeId\")==25).select(\"predError\",\"storeId\").distinct()`\n",
    "- `transactionsDf.select(\"productId\", \"storeId\").where(\"storeId == 2 OR storeId != 25\")`\n",
    "- `transactionsDf.where(col(\"value\").isNull()).select(\"productId\", \"storeId\").distinct()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|predError|storeId|\n",
      "+---------+-------+\n",
      "|        3|     25|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.filter(col(\"storeId\")==25).select(\"predError\",\"storeId\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+\n",
      "|transactionId|predError|value|storeId|productId|   f|\n",
      "+-------------+---------+-----+-------+---------+----+\n",
      "|            1|        3|    4|     25|        1|null|\n",
      "|            3|        3| null|     25|        3|null|\n",
      "|            4|     null| null|      3|        2|null|\n",
      "|            6|        3|    2|     25|        2|null|\n",
      "+-------------+---------+-----+-------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.where(col(\"storeId\").between(3,25)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+\n",
      "|transactionId|predError|value|storeId|productId|   f|\n",
      "+-------------+---------+-----+-------+---------+----+\n",
      "|            2|        6|    7|      2|        2|null|\n",
      "|            4|     null| null|      3|        2|null|\n",
      "|            5|     null| null|   null|        2|null|\n",
      "|            6|        3|    2|     25|        2|null|\n",
      "+-------------+---------+-----+-------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.filter((col(\"storeId\")!=25) | (col(\"productId\")==2)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|productId|storeId|\n",
      "+---------+-------+\n",
      "|        2|      2|\n",
      "|        2|      3|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.select(\"productId\", \"storeId\").where(\"storeId == 2 OR storeId != 25\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|productId|storeId|\n",
      "+---------+-------+\n",
      "|        2|      3|\n",
      "|        3|     25|\n",
      "|        2|   null|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.where(col(\"value\").isNull()).select(\"productId\", \"storeId\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block displayed below contains an error. The code block should count the number of rows that have a predError of either 3 or 6. Find the error.\n",
    ">\n",
    "Code block:\n",
    ">\n",
    "- `transactionsDf.filter(col(‘predError’).in([3, 6])).count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactionsDf.filter(col('predError').isin([3, 6])).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which expression is equivalent to the below expression.\n",
    ">\n",
    "- `df.where(\"salary > 5000\")`\n",
    "- `df.where(expr(\"salary > 5000\"))`\n",
    "- `df.filter(\"salary\" > 5000)`\n",
    "- `df.filter(col(\"salary\") > 5000)`\n",
    "- `df.filter(expr(\"salary > 5000\"))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Raman        |Finance   |CA   |99000 |40 |24000|\n",
      "|Scott        |Finance   |NY   |83000 |36 |19000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
    "              (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n",
    "              (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n",
    "              (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n",
    "              (\"Raman\",\"Finance\",\"CA\",99000,40,24000),\n",
    "              (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n",
    "              (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n",
    "              (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n",
    "              (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000)]\n",
    "\n",
    "schema = [\"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"]\n",
    "\n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"salary > 5000\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(expr(\"salary > 5000\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"salary\") > 5000).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(expr(\"salary > 5000\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TypeError: '>' not supported between instances of 'str' and 'int'\n",
    "df.filter(\"salary\" > 5000).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(3).where(\"salary > 4000\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"salary > 4000\").limit(3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a code as shown below to count the number of unique invoices.\n",
    "df.select(“InvoiceNo”).distinct().agg(count(“InvoiceNo”))\n",
    ">\n",
    "Choose the logically equivalent code from the options.\n",
    ">\n",
    "- `df.select(\"count(distinct InvoiceNo)\")`\n",
    "- `df.selectExpr(\"count(distinct InvoiceNo)\")`\n",
    "- `df.select(countDistinct(\"InvoiceNo\"))`\n",
    "- `df.selectExpr(\"countDistinct(InvoiceNo)\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|count(department)|\n",
      "+-----------------+\n",
      "|                3|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"department\").distinct().agg(count(\"department\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|count(DISTINCT department)|\n",
      "+--------------------------+\n",
      "|                         3|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"count(distinct department)\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|count(DISTINCT department)|\n",
      "+--------------------------+\n",
      "|                         3|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(countDistinct(\"department\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnalysisException: cannot resolve '`count(distinct department)`' given input columns: [age, bonus, department, employee_name, salary, state]\n",
    "df.select(\"count(distinct department)\").show()\n",
    "\n",
    "# AnalysisException: Undefined function: 'countDistinct'. \n",
    "# This function is neither a registered temporary function nor a permanent function registered in the database 'default'.\n",
    "df.selectExpr(\"countDistinct(department)\").show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6ad6cad6e86b8f8ebaedbe94ebc31d728d6c0d8223a99e9449734cfa4d7995"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
