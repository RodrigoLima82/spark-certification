{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# distinct().count() + countDistinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"example-count-distinct\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+\n",
      "|   Name|     Dept|Salary|\n",
      "+-------+---------+------+\n",
      "|  James|    Sales|  3000|\n",
      "|Michael|    Sales|  4600|\n",
      "| Robert|    Sales|  4100|\n",
      "|  Maria|  Finance|  3000|\n",
      "|  James|    Sales|  3000|\n",
      "|  Scott|  Finance|  3300|\n",
      "|    Jen|  Finance|  3900|\n",
      "|   Jeff|Marketing|  3000|\n",
      "|  Kumar|Marketing|  2000|\n",
      "|   Saif|    Sales|  4100|\n",
      "+-------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"James\", \"Sales\", 3000),\n",
    "        (\"Michael\", \"Sales\", 4600),\n",
    "        (\"Robert\", \"Sales\", 4100),\n",
    "        (\"Maria\", \"Finance\", 3000),\n",
    "        (\"James\", \"Sales\", 3000),\n",
    "        (\"Scott\", \"Finance\", 3300),\n",
    "        (\"Jen\", \"Finance\", 3900),\n",
    "        (\"Jeff\", \"Marketing\", 3000),\n",
    "        (\"Kumar\", \"Marketing\", 2000),\n",
    "        (\"Saif\", \"Sales\", 4100)\n",
    "      ]\n",
    "columns = [\"Name\",\"Dept\",\"Salary\"]\n",
    "df = spark.createDataFrame(data=data,schema=columns)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DataFrame distinct() and count()\n",
    "On the above DataFrame, we have a total of 10 rows and one row with all values duplicated, performing distinct count ( distinct().count() ) on this DataFrame should get us 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Count: 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Distinct Count: \" + str(df.distinct().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using countDistinct() SQL Function\n",
    ">\n",
    "DataFrame distinct() returns a new DataFrame after eliminating duplicate rows (distinct on all columns). if you want to get count distinct on selected columns, use the PySpark SQL function countDistinct(). This function returns the number of distinct elements in a group.\n",
    ">\n",
    "In order to use this function, you need to import it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|count(DISTINCT Dept, Salary)|\n",
      "+----------------------------+\n",
      "|                           8|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "df2 = df.select(countDistinct(\"Dept\", \"Salary\"))\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that countDistinct() function returns a value in a Column type hence, you need to collect it to get the value from the DataFrame. And this function can be used to get the distinct count of any number of selected or all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Count of Department & Salary: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Distinct Count of Department & Salary: \"+ str(df2.collect()[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SQL to get Count Distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      10|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"EMP\")\n",
    "spark.sql(\"select distinct(count(*)) from EMP\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT Dept)|\n",
      "+--------------------+\n",
      "|                   3|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"count(distinct Dept)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT Dept)|\n",
      "+--------------------+\n",
      "|                   3|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(countDistinct(\"Dept\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT Dept)|\n",
      "+--------------------+\n",
      "|                   3|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"count(distinct Dept)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnalysisException: Undefined function: 'countDistinct'\n",
    "df.selectExpr(\"countDistinct(Dept)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6ad6cad6e86b8f8ebaedbe94ebc31d728d6c0d8223a99e9449734cfa4d7995"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
