{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import array_contains, col, array, array_contains, explode\n",
    "from pyspark.sql.types import StringType, ArrayType, StructType, StructField, FloatType\n",
    "from pyspark.sql import functions as F\n",
    "from functools import reduce\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"example\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- languagesAtSchool: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- languagesAtWork: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- currentState: string (nullable = true)\n",
      " |-- previousState: string (nullable = true)\n",
      " |-- grade: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n",
      "+----------------+------------------+---------------+------------+-------------+--------------------+\n",
      "|            name| languagesAtSchool|languagesAtWork|currentState|previousState|               grade|\n",
      "+----------------+------------------+---------------+------------+-------------+--------------------+\n",
      "|    James,,Smith|[Java, Scala, C++]|  [Spark, Java]|          OH|           CA|[1.0, 2.1, 3.2, 4...|\n",
      "|   Michael,Rose,|[Spark, Java, C++]|  [Spark, Java]|          NY|           NJ|[2.0, 3.1, 4.2, 5...|\n",
      "|Robert,,Williams|      [CSharp, VB]|[Spark, Python]|          UT|           NV|[3.0, 4.1, 5.2, 6...|\n",
      "+----------------+------------------+---------------+------------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arrayCol = ArrayType(StringType(),False)\n",
    "\n",
    "data = [(\"James,,Smith\", [\"Java\",\"Scala\",\"C++\"], [\"Spark\",\"Java\"], \"OH\", \"CA\", [1.0,2.1,3.2,4.3,5.4]),\n",
    "        (\"Michael,Rose,\", [\"Spark\",\"Java\",\"C++\"], [\"Spark\",\"Java\"], \"NY\", \"NJ\",[2.0,3.1,4.2,5.3,6.4]),\n",
    "        (\"Robert,,Williams\", [\"CSharp\",\"VB\"], [\"Spark\",\"Python\"], \"UT\", \"NV\",[3.0,4.1,5.2,6.3,7.4])]\n",
    "\n",
    "schema = StructType([ \n",
    "    StructField(\"name\",StringType(),True), \n",
    "    StructField(\"languagesAtSchool\",ArrayType(StringType()),True), \n",
    "    StructField(\"languagesAtWork\",ArrayType(StringType()),True), \n",
    "    StructField(\"currentState\", StringType(), True), \n",
    "    StructField(\"previousState\", StringType(), True),\n",
    "    StructField(\"grade\",ArrayType(FloatType()),True), \n",
    "  ])\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|avg|\n",
      "+---+\n",
      "|3.2|\n",
      "|4.2|\n",
      "|5.2|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "array_mean = udf(lambda x: float(np.mean(x)), FloatType())\n",
    "df.select(array_mean(\"grade\").alias(\"avg\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+---------------+------------+-------------+--------------------+-----------------+\n",
      "|            name| languagesAtSchool|languagesAtWork|currentState|previousState|               grade|        avg_grade|\n",
      "+----------------+------------------+---------------+------------+-------------+--------------------+-----------------+\n",
      "|    James,,Smith|[Java, Scala, C++]|  [Spark, Java]|          OH|           CA|[1.0, 2.1, 3.2, 4...|3.200000047683716|\n",
      "|   Michael,Rose,|[Spark, Java, C++]|  [Spark, Java]|          NY|           NJ|[2.0, 3.1, 4.2, 5...|              4.2|\n",
      "|Robert,,Williams|      [CSharp, VB]|[Spark, Python]|          UT|           NV|[3.0, 4.1, 5.2, 6...|              5.2|\n",
      "+----------------+------------------+---------------+------------+-------------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "query = \"\"\"aggregate(`{col}`, CAST(0.0 AS double), (acc, x) -> acc + x, acc -> acc / size(`{col}`)) AS  `avg_{col}`\"\"\".format(col=\"grade\")\n",
    "\n",
    "df.selectExpr(\"*\", query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_null = expr(\"\"\"aggregate(\n",
    "                    CAST(array(_1, _2, _3) AS array<double>), \n",
    "                    CAST((0.0 as sum, 0.0 as n) AS struct<sum: double, n: double>), \n",
    "                    (acc, x) -> (\n",
    "                        acc.sum + coalesce(x, 0.0), \n",
    "                        acc.n + CASE WHEN x IS NULL THEN 0.0 ELSE 1.0 END), \n",
    "                    acc -> acc.sum / acc.n)\"\"\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6ad6cad6e86b8f8ebaedbe94ebc31d728d6c0d8223a99e9449734cfa4d7995"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
