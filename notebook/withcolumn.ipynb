{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITHCOLUMN() + WITHCOLUMNRENAMED()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"example-withcolumn-2\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "        ('Michael','Rose','','2000-05-19','M',4000),\n",
    "        ('Robert','','Williams','1978-09-05','M',4000),\n",
    "        ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "        ('Jen','Mary','Brown','1980-02-17','F',-1)]\n",
    "\n",
    "columns = [\"firstname\", \"middlename\", \"lastname\", \"dob\", \"gender\", \"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change DataType using PySpark withColumn()\n",
    "df.withColumn(\"salary\",col(\"salary\").cast(\"Integer\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update The Value of an Existing Column\n",
    "df.withColumn(\"salary\", col(\"salary\") * 10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update The Value of an Existing Column - squared value of column salary\n",
    "df.withColumn(\"new_salary\", pow(col(\"salary\"), lit(2))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Column Name\n",
    "df.withColumnRenamed(\"gender\",\"sex\").show(truncate=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Column From PySpark DataFrame\n",
    "df.drop(\"new_salary\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+----------------+----------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|salary_increment|new_salary|\n",
      "+---------+----------+--------+----------+------+------+----------------+----------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000|          450.00|   3450.00|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|          600.00|   4600.00|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|          600.00|   4600.00|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|          600.00|   4600.00|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|           -0.15|     -1.15|\n",
      "+---------+----------+--------+----------+------+------+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"salary_increment\", expr(\"salary * 0.15\")) \\\n",
    "  .withColumn(\"new_salary\", expr(\"salary + salary_increment\")) \\\n",
    "  .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a DataFrame with an added column to DataFrame transactionsDf that shows the unix epoch timestamps in column transactionDate as strings in the format month/day/year in column transactionDateFormatted?\n",
    ">\n",
    "\n",
    "- `+————————————-+—————————+—–———+——————-+—————————+———-+———————————————+`\n",
    "- `|transactionId|predError|value|storeId|productId| f  |transactionDate|`\n",
    "- `+————————————-+—————————+————–+——————-+—————————+———-+———————————————+`\n",
    "- `| 1           | 3       | 4   | 25    | 1       |null| 1587915332    |`\n",
    "- `| 2           | 6       | 7   | 2     | 2       |null| 1586815312    |`\n",
    "- `| 3           | 3       | null| 25    | 3       |null| 1585824821    |`\n",
    "- `| 4           | null    | null| 3     | 2       |null| 1583244275    |`\n",
    "- `| 5           | null    | null| null  | 2       |null| 1575285427    |`\n",
    "- `| 6           | 3       | 2   | 25    | 2       |null| 1572733275    |`\n",
    "- `+————————————-+—————————+—–———+——————-+—————————+———-+———————————————+`\n",
    "\n",
    ">\n",
    "- `transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\", format=\"dd/MM/yyyy\"))`\n",
    "- `transactionsDf.withColumnRenamed(\"transactionDate\", \"transactionDateFormatted\", from_unixtime(\"transactionDateFormatted\", format=\"MM/dd/yyyy\"))`\n",
    "- `transactionsDf.apply(from_unixtime(format=\"MM/dd/yyyy\")).asColumn(\"transactionDateFormatted\")`\n",
    "- `transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\", format=\"MM/dd/yyyy\"))`\n",
    "- `transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\"))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1, 3, 4, 25, 1, None, 1587915332),\n",
    "         (2, 6, 7, 2, 2, None, 1586815312),\n",
    "         (3, 3, None, 25, 3, None, 1585824821),\n",
    "         (4, None, None, 3, 2, None, 1583244275),\n",
    "         (5, None, None, None, 2, None, 1575285427),\n",
    "         (6, 3, 2, 25, 2, None, 1572733275)]\n",
    "\n",
    "schema = StructType([StructField('transactionId', IntegerType(), True),\n",
    "                     StructField('predError', IntegerType(), True),\n",
    "                     StructField('value', IntegerType(), True),\n",
    "                     StructField('storeId', IntegerType(), True),\n",
    "                     StructField('productId', IntegerType(), True),\n",
    "                     StructField('f', IntegerType(), True),\n",
    "                     StructField('transactionDate', LongType(), True)])\n",
    "\n",
    "transactionsDf = spark.createDataFrame(data=data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactionsDf.printSchema()\n",
    "transactionsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\", format=\"dd/MM/yyyy\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\", format=\"MM/dd/yyyy\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TypeError: withColumnRenamed() takes 3 positional arguments but 4 were given\n",
    "transactionsDf.withColumnRenamed(\"transactionDate\", \"transactionDateFormatted\", from_unixtime(\"transactionDateFormatted\", format=\"MM/dd/yyyy\")).show()\n",
    "\n",
    "# AttributeError: 'DataFrame' object has no attribute 'apply'\n",
    "transactionsDf.apply(from_unixtime(format=\"MM/dd/yyyy\")).asColumn(\"transactionDateFormatted\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block displayed below contains an error. The code block should use Python method find_most_freq_letter to find the letter present most in column itemName of DataFrame itemsDf and return it in a new column most_frequent_letter. Find the error.\n",
    ">\n",
    "Code block:\n",
    ">\n",
    "- `find_most_freq_letter_udf = udf(find_most_freq_letter)`\n",
    "- `itemsDf.withColumn(“most_frequent_letter”, find_most_freq_letter(“itemName”))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block shown below should return a copy of DataFrame transactionsDf without columns value and productId and with an additional column associateId that has the value 5. Choose the answer that correctly fills the blanks in the code block to accomplish this.\n",
    ">\n",
    "- `transactionsDf.__1__(__2__, __3__).__4__(__5__, ‘value’)`\n",
    ">\n",
    "- `1. withColumn 2. 'associateId' 3. 5 4. remove 5. 'productId'`\n",
    "- `1. withNewColumn 2. associateId 3. lit(5) 4. drop 5. productId`\n",
    "- `1. withColumn 2. 'associateId' 3. lit(5) 4. drop 5. 'productId'`\n",
    "- `1. withColumnRenamed 2. 'associateId' 3. 5 4. drop 5. 'productId'`\n",
    "- `1. withColumn 2. col(associateId) 3. lit(5) 4. drop 5. col(productId)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactionsDf.withColumn('associateId', lit(5)).drop('productId', 'value').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AssertionError: col should be Column\n",
    "transactionsDf.withColumn('associateId', 5).remove('productId', 'value')\n",
    "\n",
    "# AttributeError: 'DataFrame' object has no attribute 'withNewColumn'\n",
    "transactionsDf.withNewColumn('associateId', lit(5)).drop(productId, 'value')\n",
    "\n",
    "# Py4JError: An error occurred while calling o133.withColumnRenamed\n",
    "transactionsDf.withColumnRenamed('associateId', 5).drop('productId', 'value').show()\n",
    "\n",
    "# col(productId)\n",
    "transactionsDf.withColumn(col(associateId), lit(5)).drop(col(productId), 'value').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks adds a column predErrorSqrt to DataFrame transactionsDf that is the square root of column predError?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactionsDf.withColumn(\"predErrorSqrt\", sqrt(col(\"predError\"))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactionsDf.select(sqrt(\"predError\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NameError: name 'predError' is not defined\n",
    "transactionsDf.withColumn(\"predErrorSqrt\", sqrt(predError))\n",
    "\n",
    "# NameError: name 'predError' is not defined\n",
    "transactionsDf.select(sqrt(predError))\n",
    "\n",
    "# TypeError: 'Column' object is not callable\n",
    "transactionsDf.withColumn(\"predErrorSqrt\", col(\"predError\").sqrt())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a copy of DataFrame transactionsDf where the column storeId has been converted to string type?\n",
    "\n",
    ">\n",
    "\n",
    "- `transactionsDf.withColumn(\"storeId\", convert(\"storeId\", \"string\"))`\n",
    "- `transactionsDf.withColumn(\"storeId\", col(\"storeId\", \"string\"))`\n",
    "- `transactionsDf.withColumn(\"storeId\", col(\"storeId\").convert(\"string\"))`\n",
    "- `transactionsDf.withColumn(\"storeId\", col(\"storeId\").cast(\"string\"))`\n",
    "- `transactionsDf.withColumn(\"storeId\", convert(\"storeId\").as(\"string\"))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactionsDf.withColumn(\"storeId\", col(\"storeId\").cast(\"string\")).printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NameError: name 'convert' is not defined\n",
    "transactionsDf.withColumn(\"storeId\", convert(\"storeId\", \"string\"))\n",
    "\n",
    "# TypeError: _() takes 1 positional argument but 2 were given\n",
    "transactionsDf.withColumn(\"storeId\", col(\"storeId\", \"string\"))\n",
    "\n",
    "# TypeError: 'Column' object is not callable\n",
    "transactionsDf.withColumn(\"storeId\", col(\"storeId\").convert(\"string\"))\n",
    "\n",
    "# SyntaxError: invalid syntax\n",
    "transactionsDf.withColumn(\"storeId\", convert(\"storeId\").as(\"string\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a DataFrame with a new column salary_increment and all previously existing columns.\n",
    ">\n",
    "- `df.selectExpr(\"*\", \"salary * 0.15\")`\n",
    "- `df.withColumn(\"salary_increment\", expr(\"salary * 0.15\"))`\n",
    "- `df.withColumn(\"salary_increment\", \"salary * 0.15\")`\n",
    "- `df.selectExpr(\"*\", \"salary * 0.15 as salary_increment\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.selectExpr(\"*\", \"salary * 0.15\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"salary_increment\", expr(\"salary * 0.15\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.selectExpr(\"*\", \"salary * 0.15 as salary_increment\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AssertionError: col should be Column\n",
    "df.withColumn(\"salary_increment\", \"salary * 0.15\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a DataFrame as shown below.\n",
    ">\n",
    "- `+——-+—-+———-+`\n",
    "- `|BatchID|Year|CourseName|`\n",
    "- `+——-+—-+———-+`\n",
    "- `| X1 |2020| Scala |`\n",
    "- `| X2 |2020| Python |`\n",
    "- `| X3 |null| Java |`\n",
    "- `| X4 |2021| Scala |`\n",
    "- `| X5 |null| Python |`\n",
    "- `| X6 |2021| Spark |`\n",
    "- `+——-+—-+———-+`\n",
    ">\n",
    "You want to transform the Year column and replace all nulls with the value 2021. Choose the correct option from the given code blocks.\n",
    ">\n",
    "- `df.withColumn(\"Year\", coalesce(col(\"Year\"), \"2021\"))`\n",
    "- `df.withColumn(\"Year\", coalesce(col(\"Year\"), lit(\"2021\")))`\n",
    "- `df.withColumn(\"Year\", coalesce(col(\"Year\"), col(\"2021\")))`\n",
    "- `df.withColumn(\"Year\", coalesce(col(\"Year\"), expr(\"2021\")))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- BatchID: string (nullable = true)\n",
      " |-- Year: long (nullable = true)\n",
      " |-- CourseName: string (nullable = true)\n",
      "\n",
      "+-------+----+----------+\n",
      "|BatchID|Year|CourseName|\n",
      "+-------+----+----------+\n",
      "|     X1|2020|     Scala|\n",
      "|     X2|2020|    Python|\n",
      "|     X3|null|      Java|\n",
      "|     X4|2021|     Scala|\n",
      "|     X5|null|    Python|\n",
      "|     X6|2021|     Spark|\n",
      "+-------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "        ('X1',2020,'Scala'),\n",
    "        ('X2',2020,'Python'),\n",
    "        ('X3',None,'Java'),\n",
    "        ('X4',2021,'Scala'),\n",
    "        ('X5',None,'Python'),\n",
    "        ('X6',2021,'Spark')]\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema = ['BatchID','Year','CourseName'])\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"Year\", coalesce(col(\"Year\"), lit(\"2021\"))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"Year\", coalesce(col(\"Year\"), expr(\"2021\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnalysisException: cannot resolve '`2021`' given input columns: [BatchID, CourseName, Year]\n",
    "df.withColumn(\"Year\", coalesce(col(\"Year\"), \"2021\"))\n",
    "\n",
    "# AnalysisException: cannot resolve '`2021`' given input columns: [BatchID, CourseName, Year]\n",
    "df.withColumn(\"Year\", coalesce(col(\"Year\"), col(\"2021\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which function will you use to add a new field in your DataFrame with a current timestamp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"now\", current_timestamp()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+\n",
      "|BatchID|Year|CourseName|\n",
      "+-------+----+----------+\n",
      "|     X1|2020|     Scala|\n",
      "|     X2|2020|    Python|\n",
      "|     X3|2021|      Java|\n",
      "|     X4|2021|     Scala|\n",
      "|     X5|2021|    Python|\n",
      "|     X6|2021|     Spark|\n",
      "+-------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Year\", expr(\"ifnull(Year, '2021')\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6ad6cad6e86b8f8ebaedbe94ebc31d728d6c0d8223a99e9449734cfa4d7995"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
