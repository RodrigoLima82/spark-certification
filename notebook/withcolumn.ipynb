{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITHCOLUMN() + WITHCOLUMNRENAMED()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"example-withcolumn\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "        ('Michael','Rose','','2000-05-19','M',4000),\n",
    "        ('Robert','','Williams','1978-09-05','M',4000),\n",
    "        ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "        ('Jen','Mary','Brown','1980-02-17','F',-1)]\n",
    "\n",
    "columns = [\"firstname\", \"middlename\", \"lastname\", \"dob\", \"gender\", \"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change DataType using PySpark withColumn()\n",
    "df.withColumn(\"salary\",col(\"salary\").cast(\"Integer\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|    James|          |   Smith|1991-04-01|     M| 30000|\n",
      "|  Michael|      Rose|        |2000-05-19|     M| 40000|\n",
      "|   Robert|          |Williams|1978-09-05|     M| 40000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F| 40000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|   -10|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update The Value of an Existing Column\n",
    "df.withColumn(\"salary\", col(\"salary\") * 10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+----------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|new_salary|\n",
      "+---------+----------+--------+----------+------+------+----------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000| 9000000.0|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|     1.6E7|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|     1.6E7|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|     1.6E7|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|       1.0|\n",
      "+---------+----------+--------+----------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update The Value of an Existing Column - squared value of column salary\n",
    "df.withColumn(\"new_salary\", pow(col(\"salary\"), lit(2))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+---+------+\n",
      "|firstname|middlename|lastname|dob       |sex|salary|\n",
      "+---------+----------+--------+----------+---+------+\n",
      "|James    |          |Smith   |1991-04-01|M  |3000  |\n",
      "|Michael  |Rose      |        |2000-05-19|M  |4000  |\n",
      "|Robert   |          |Williams|1978-09-05|M  |4000  |\n",
      "|Maria    |Anne      |Jones   |1967-12-01|F  |4000  |\n",
      "|Jen      |Mary      |Brown   |1980-02-17|F  |-1    |\n",
      "+---------+----------+--------+----------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename Column Name\n",
    "df.withColumnRenamed(\"gender\",\"sex\").show(truncate=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop Column From PySpark DataFrame\n",
    "df.drop(\"new_salary\").show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a DataFrame with an added column to DataFrame transactionsDf that shows the unix epoch timestamps in column transactionDate as strings in the format month/day/year in column transactionDateFormatted?\n",
    ">\n",
    "\n",
    "- `+————————————-+—————————+—–———+——————-+—————————+———-+———————————————+`\n",
    "- `|transactionId|predError|value|storeId|productId| f  |transactionDate|`\n",
    "- `+————————————-+—————————+————–+——————-+—————————+———-+———————————————+`\n",
    "- `| 1           | 3       | 4   | 25    | 1       |null| 1587915332    |`\n",
    "- `| 2           | 6       | 7   | 2     | 2       |null| 1586815312    |`\n",
    "- `| 3           | 3       | null| 25    | 3       |null| 1585824821    |`\n",
    "- `| 4           | null    | null| 3     | 2       |null| 1583244275    |`\n",
    "- `| 5           | null    | null| null  | 2       |null| 1575285427    |`\n",
    "- `| 6           | 3       | 2   | 25    | 2       |null| 1572733275    |`\n",
    "- `+————————————-+—————————+—–———+——————-+—————————+———-+———————————————+`\n",
    "\n",
    ">\n",
    "- `transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\", format=\"dd/MM/yyyy\"))`\n",
    "- `transactionsDf.withColumnRenamed(\"transactionDate\", \"transactionDateFormatted\", from_unixtime(\"transactionDateFormatted\", format=\"MM/dd/yyyy\"))`\n",
    "- `transactionsDf.apply(from_unixtime(format=\"MM/dd/yyyy\")).asColumn(\"transactionDateFormatted\")`\n",
    "- `transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\", format=\"MM/dd/yyyy\"))`\n",
    "- `transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\"))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1, 3, 4, 25, 1, None, 1587915332),\n",
    "         (2, 6, 7, 2, 2, None, 1586815312),\n",
    "         (3, 3, None, 25, 3, None, 1585824821),\n",
    "         (4, None, None, 3, 2, None, 1583244275),\n",
    "         (5, None, None, None, 2, None, 1575285427),\n",
    "         (6, 3, 2, 25, 2, None, 1572733275)]\n",
    "\n",
    "schema = StructType([StructField('transactionId', IntegerType(), True),\n",
    "                     StructField('predError', IntegerType(), True),\n",
    "                     StructField('value', IntegerType(), True),\n",
    "                     StructField('storeId', IntegerType(), True),\n",
    "                     StructField('productId', IntegerType(), True),\n",
    "                     StructField('f', IntegerType(), True),\n",
    "                     StructField('transactionDate', LongType(), True)])\n",
    "\n",
    "transactionsDf = spark.createDataFrame(data=data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transactionId: integer (nullable = true)\n",
      " |-- predError: integer (nullable = true)\n",
      " |-- value: integer (nullable = true)\n",
      " |-- storeId: integer (nullable = true)\n",
      " |-- productId: integer (nullable = true)\n",
      " |-- f: integer (nullable = true)\n",
      " |-- transactionDate: long (nullable = true)\n",
      "\n",
      "+-------------+---------+-----+-------+---------+----+---------------+\n",
      "|transactionId|predError|value|storeId|productId|   f|transactionDate|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+\n",
      "|            1|        3|    4|     25|        1|null|     1587915332|\n",
      "|            2|        6|    7|      2|        2|null|     1586815312|\n",
      "|            3|        3| null|     25|        3|null|     1585824821|\n",
      "|            4|     null| null|      3|        2|null|     1583244275|\n",
      "|            5|     null| null|   null|        2|null|     1575285427|\n",
      "|            6|        3|    2|     25|        2|null|     1572733275|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.printSchema()\n",
    "transactionsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "|transactionId|predError|value|storeId|productId|   f|transactionDate|transactionDateFormatted|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "|            1|        3|    4|     25|        1|null|     1587915332|              26/04/2020|\n",
      "|            2|        6|    7|      2|        2|null|     1586815312|              13/04/2020|\n",
      "|            3|        3| null|     25|        3|null|     1585824821|              02/04/2020|\n",
      "|            4|     null| null|      3|        2|null|     1583244275|              03/03/2020|\n",
      "|            5|     null| null|   null|        2|null|     1575285427|              02/12/2019|\n",
      "|            6|        3|    2|     25|        2|null|     1572733275|              02/11/2019|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\", format=\"dd/MM/yyyy\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "|transactionId|predError|value|storeId|productId|   f|transactionDate|transactionDateFormatted|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "|            1|        3|    4|     25|        1|null|     1587915332|              04/26/2020|\n",
      "|            2|        6|    7|      2|        2|null|     1586815312|              04/13/2020|\n",
      "|            3|        3| null|     25|        3|null|     1585824821|              04/02/2020|\n",
      "|            4|     null| null|      3|        2|null|     1583244275|              03/03/2020|\n",
      "|            5|     null| null|   null|        2|null|     1575285427|              12/02/2019|\n",
      "|            6|        3|    2|     25|        2|null|     1572733275|              11/02/2019|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\", format=\"MM/dd/yyyy\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "|transactionId|predError|value|storeId|productId|   f|transactionDate|transactionDateFormatted|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "|            1|        3|    4|     25|        1|null|     1587915332|     2020-04-26 12:35:32|\n",
      "|            2|        6|    7|      2|        2|null|     1586815312|     2020-04-13 19:01:52|\n",
      "|            3|        3| null|     25|        3|null|     1585824821|     2020-04-02 07:53:41|\n",
      "|            4|     null| null|      3|        2|null|     1583244275|     2020-03-03 11:04:35|\n",
      "|            5|     null| null|   null|        2|null|     1575285427|     2019-12-02 09:17:07|\n",
      "|            6|        3|    2|     25|        2|null|     1572733275|     2019-11-02 19:21:15|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TypeError: withColumnRenamed() takes 3 positional arguments but 4 were given\n",
    "transactionsDf.withColumnRenamed(\"transactionDate\", \"transactionDateFormatted\", from_unixtime(\"transactionDateFormatted\", format=\"MM/dd/yyyy\")).show()\n",
    "\n",
    "# AttributeError: 'DataFrame' object has no attribute 'apply'\n",
    "transactionsDf.apply(from_unixtime(format=\"MM/dd/yyyy\")).asColumn(\"transactionDateFormatted\").show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6ad6cad6e86b8f8ebaedbe94ebc31d728d6c0d8223a99e9449734cfa4d7995"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
