{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITHCOLUMN() + WITHCOLUMNRENAMED()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"example-withcolumn-2\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "        ('Michael','Rose','','2000-05-19','M',4000),\n",
    "        ('Robert','','Williams','1978-09-05','M',4000),\n",
    "        ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "        ('Jen','Mary','Brown','1980-02-17','F',-1)]\n",
    "\n",
    "columns = [\"firstname\", \"middlename\", \"lastname\", \"dob\", \"gender\", \"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change DataType using PySpark withColumn()\n",
    "df.withColumn(\"salary\",col(\"salary\").cast(\"Integer\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|    James|          |   Smith|1991-04-01|     M| 30000|\n",
      "|  Michael|      Rose|        |2000-05-19|     M| 40000|\n",
      "|   Robert|          |Williams|1978-09-05|     M| 40000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F| 40000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|   -10|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update The Value of an Existing Column\n",
    "df.withColumn(\"salary\", col(\"salary\") * 10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+----------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|new_salary|\n",
      "+---------+----------+--------+----------+------+------+----------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000| 9000000.0|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|     1.6E7|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|     1.6E7|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|     1.6E7|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|       1.0|\n",
      "+---------+----------+--------+----------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update The Value of an Existing Column - squared value of column salary\n",
    "df.withColumn(\"new_salary\", pow(col(\"salary\"), lit(2))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+---+------+\n",
      "|firstname|middlename|lastname|dob       |sex|salary|\n",
      "+---------+----------+--------+----------+---+------+\n",
      "|James    |          |Smith   |1991-04-01|M  |3000  |\n",
      "|Michael  |Rose      |        |2000-05-19|M  |4000  |\n",
      "|Robert   |          |Williams|1978-09-05|M  |4000  |\n",
      "|Maria    |Anne      |Jones   |1967-12-01|F  |4000  |\n",
      "|Jen      |Mary      |Brown   |1980-02-17|F  |-1    |\n",
      "+---------+----------+--------+----------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename Column Name\n",
    "df.withColumnRenamed(\"gender\",\"sex\").show(truncate=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Column From PySpark DataFrame\n",
    "df.drop(\"new_salary\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"salary_increment\", expr(\"salary * 0.15\")) \\\n",
    "  .withColumn(\"new_salary\", expr(\"salary + salary_increment\")) \\\n",
    "  .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a DataFrame with an added column to DataFrame transactionsDf that shows the unix epoch timestamps in column transactionDate as strings in the format month/day/year in column transactionDateFormatted?\n",
    ">\n",
    "\n",
    "- `+————————————-+—————————+—–———+——————-+—————————+———-+———————————————+`\n",
    "- `|transactionId|predError|value|storeId|productId| f  |transactionDate|`\n",
    "- `+————————————-+—————————+————–+——————-+—————————+———-+———————————————+`\n",
    "- `| 1           | 3       | 4   | 25    | 1       |null| 1587915332    |`\n",
    "- `| 2           | 6       | 7   | 2     | 2       |null| 1586815312    |`\n",
    "- `| 3           | 3       | null| 25    | 3       |null| 1585824821    |`\n",
    "- `| 4           | null    | null| 3     | 2       |null| 1583244275    |`\n",
    "- `| 5           | null    | null| null  | 2       |null| 1575285427    |`\n",
    "- `| 6           | 3       | 2   | 25    | 2       |null| 1572733275    |`\n",
    "- `+————————————-+—————————+—–———+——————-+—————————+———-+———————————————+`\n",
    "\n",
    ">\n",
    "- `transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\", format=\"dd/MM/yyyy\"))`\n",
    "- `transactionsDf.withColumnRenamed(\"transactionDate\", \"transactionDateFormatted\", from_unixtime(\"transactionDateFormatted\", format=\"MM/dd/yyyy\"))`\n",
    "- `transactionsDf.apply(from_unixtime(format=\"MM/dd/yyyy\")).asColumn(\"transactionDateFormatted\")`\n",
    "- `transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\", format=\"MM/dd/yyyy\"))`\n",
    "- `transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\"))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1, 3, 4, 25, 1, None, 1587915332),\n",
    "         (2, 6, 7, 2, 2, None, 1586815312),\n",
    "         (3, 3, None, 25, 3, None, 1585824821),\n",
    "         (4, None, None, 3, 2, None, 1583244275),\n",
    "         (5, None, None, None, 2, None, 1575285427),\n",
    "         (6, 3, 2, 25, 2, None, 1572733275)]\n",
    "\n",
    "schema = StructType([StructField('transactionId', IntegerType(), True),\n",
    "                     StructField('predError', IntegerType(), True),\n",
    "                     StructField('value', IntegerType(), True),\n",
    "                     StructField('storeId', IntegerType(), True),\n",
    "                     StructField('productId', IntegerType(), True),\n",
    "                     StructField('f', IntegerType(), True),\n",
    "                     StructField('transactionDate', LongType(), True)])\n",
    "\n",
    "transactionsDf = spark.createDataFrame(data=data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transactionId: integer (nullable = true)\n",
      " |-- predError: integer (nullable = true)\n",
      " |-- value: integer (nullable = true)\n",
      " |-- storeId: integer (nullable = true)\n",
      " |-- productId: integer (nullable = true)\n",
      " |-- f: integer (nullable = true)\n",
      " |-- transactionDate: long (nullable = true)\n",
      "\n",
      "+-------------+---------+-----+-------+---------+----+---------------+\n",
      "|transactionId|predError|value|storeId|productId|   f|transactionDate|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+\n",
      "|            1|        3|    4|     25|        1|null|     1587915332|\n",
      "|            2|        6|    7|      2|        2|null|     1586815312|\n",
      "|            3|        3| null|     25|        3|null|     1585824821|\n",
      "|            4|     null| null|      3|        2|null|     1583244275|\n",
      "|            5|     null| null|   null|        2|null|     1575285427|\n",
      "|            6|        3|    2|     25|        2|null|     1572733275|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.printSchema()\n",
    "transactionsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "|transactionId|predError|value|storeId|productId|   f|transactionDate|transactionDateFormatted|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "|            1|        3|    4|     25|        1|null|     1587915332|              26/04/2020|\n",
      "|            2|        6|    7|      2|        2|null|     1586815312|              13/04/2020|\n",
      "|            3|        3| null|     25|        3|null|     1585824821|              02/04/2020|\n",
      "|            4|     null| null|      3|        2|null|     1583244275|              03/03/2020|\n",
      "|            5|     null| null|   null|        2|null|     1575285427|              02/12/2019|\n",
      "|            6|        3|    2|     25|        2|null|     1572733275|              02/11/2019|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\", format=\"dd/MM/yyyy\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "|transactionId|predError|value|storeId|productId|   f|transactionDate|transactionDateFormatted|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "|            1|        3|    4|     25|        1|null|     1587915332|              04/26/2020|\n",
      "|            2|        6|    7|      2|        2|null|     1586815312|              04/13/2020|\n",
      "|            3|        3| null|     25|        3|null|     1585824821|              04/02/2020|\n",
      "|            4|     null| null|      3|        2|null|     1583244275|              03/03/2020|\n",
      "|            5|     null| null|   null|        2|null|     1575285427|              12/02/2019|\n",
      "|            6|        3|    2|     25|        2|null|     1572733275|              11/02/2019|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\", format=\"MM/dd/yyyy\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "|transactionId|predError|value|storeId|productId|   f|transactionDate|transactionDateFormatted|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "|            1|        3|    4|     25|        1|null|     1587915332|     2020-04-26 12:35:32|\n",
      "|            2|        6|    7|      2|        2|null|     1586815312|     2020-04-13 19:01:52|\n",
      "|            3|        3| null|     25|        3|null|     1585824821|     2020-04-02 07:53:41|\n",
      "|            4|     null| null|      3|        2|null|     1583244275|     2020-03-03 11:04:35|\n",
      "|            5|     null| null|   null|        2|null|     1575285427|     2019-12-02 09:17:07|\n",
      "|            6|        3|    2|     25|        2|null|     1572733275|     2019-11-02 19:21:15|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.withColumn(\"transactionDateFormatted\", from_unixtime(\"transactionDate\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "withColumnRenamed() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9ff21821859a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TypeError: withColumnRenamed() takes 3 positional arguments but 4 were given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtransactionsDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transactionDate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transactionDateFormatted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_unixtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transactionDateFormatted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MM/dd/yyyy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# AttributeError: 'DataFrame' object has no attribute 'apply'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtransactionsDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_unixtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MM/dd/yyyy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transactionDateFormatted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: withColumnRenamed() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# TypeError: withColumnRenamed() takes 3 positional arguments but 4 were given\n",
    "transactionsDf.withColumnRenamed(\"transactionDate\", \"transactionDateFormatted\", from_unixtime(\"transactionDateFormatted\", format=\"MM/dd/yyyy\")).show()\n",
    "\n",
    "# AttributeError: 'DataFrame' object has no attribute 'apply'\n",
    "transactionsDf.apply(from_unixtime(format=\"MM/dd/yyyy\")).asColumn(\"transactionDateFormatted\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block displayed below contains an error. The code block should use Python method find_most_freq_letter to find the letter present most in column itemName of DataFrame itemsDf and return it in a new column most_frequent_letter. Find the error.\n",
    ">\n",
    "Code block:\n",
    ">\n",
    "- `find_most_freq_letter_udf = udf(find_most_freq_letter)`\n",
    "- `itemsDf.withColumn(“most_frequent_letter”, find_most_freq_letter(“itemName”))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block shown below should return a copy of DataFrame transactionsDf without columns value and productId and with an additional column associateId that has the value 5. Choose the answer that correctly fills the blanks in the code block to accomplish this.\n",
    ">\n",
    "- `transactionsDf.__1__(__2__, __3__).__4__(__5__, ‘value’)`\n",
    ">\n",
    "- `1. withColumn 2. 'associateId' 3. 5 4. remove 5. 'productId'`\n",
    "- `1. withNewColumn 2. associateId 3. lit(5) 4. drop 5. productId`\n",
    "- `1. withColumn 2. 'associateId' 3. lit(5) 4. drop 5. 'productId'`\n",
    "- `1. withColumnRenamed 2. 'associateId' 3. 5 4. drop 5. 'productId'`\n",
    "- `1. withColumn 2. col(associateId) 3. lit(5) 4. drop 5. col(productId)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-------+----+---------------+-----------+\n",
      "|transactionId|predError|storeId|   f|transactionDate|associateId|\n",
      "+-------------+---------+-------+----+---------------+-----------+\n",
      "|            1|        3|     25|null|     1587915332|          5|\n",
      "|            2|        6|      2|null|     1586815312|          5|\n",
      "|            3|        3|     25|null|     1585824821|          5|\n",
      "|            4|     null|      3|null|     1583244275|          5|\n",
      "|            5|     null|   null|null|     1575285427|          5|\n",
      "|            6|        3|     25|null|     1572733275|          5|\n",
      "+-------------+---------+-------+----+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.withColumn('associateId', lit(5)).drop('productId', 'value').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "col should be Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-279e32ad710f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# AssertionError: col should be Column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtransactionsDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'associateId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'productId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# AttributeError: 'DataFrame' object has no attribute 'withNewColumn'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtransactionsDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithNewColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'associateId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproductId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \"\"\"\n\u001b[1;32m   2476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2477\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2478\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: col should be Column"
     ]
    }
   ],
   "source": [
    "# AssertionError: col should be Column\n",
    "transactionsDf.withColumn('associateId', 5).remove('productId', 'value')\n",
    "\n",
    "# AttributeError: 'DataFrame' object has no attribute 'withNewColumn'\n",
    "transactionsDf.withNewColumn('associateId', lit(5)).drop(productId, 'value')\n",
    "\n",
    "# Py4JError: An error occurred while calling o133.withColumnRenamed\n",
    "transactionsDf.withColumnRenamed('associateId', 5).drop('productId', 'value').show()\n",
    "\n",
    "# col(productId)\n",
    "transactionsDf.withColumn(col(associateId), lit(5)).drop(col(productId), 'value').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks adds a column predErrorSqrt to DataFrame transactionsDf that is the square root of column predError?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+-------+---------+----+---------------+------------------+\n",
      "|transactionId|predError|value|storeId|productId|   f|transactionDate|     predErrorSqrt|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------+\n",
      "|            1|        3|    4|     25|        1|null|     1587915332|1.7320508075688772|\n",
      "|            2|        6|    7|      2|        2|null|     1586815312| 2.449489742783178|\n",
      "|            3|        3| null|     25|        3|null|     1585824821|1.7320508075688772|\n",
      "|            4|     null| null|      3|        2|null|     1583244275|              null|\n",
      "|            5|     null| null|   null|        2|null|     1575285427|              null|\n",
      "|            6|        3|    2|     25|        2|null|     1572733275|1.7320508075688772|\n",
      "+-------------+---------+-----+-------+---------+----+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.withColumn(\"predErrorSqrt\", sqrt(col(\"predError\"))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|   SQRT(predError)|\n",
      "+------------------+\n",
      "|1.7320508075688772|\n",
      "| 2.449489742783178|\n",
      "|1.7320508075688772|\n",
      "|              null|\n",
      "|              null|\n",
      "|1.7320508075688772|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.select(sqrt(\"predError\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NameError: name 'predError' is not defined\n",
    "transactionsDf.withColumn(\"predErrorSqrt\", sqrt(predError))\n",
    "\n",
    "# NameError: name 'predError' is not defined\n",
    "transactionsDf.select(sqrt(predError))\n",
    "\n",
    "# TypeError: 'Column' object is not callable\n",
    "transactionsDf.withColumn(\"predErrorSqrt\", col(\"predError\").sqrt())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a copy of DataFrame transactionsDf where the column storeId has been converted to string type?\n",
    "\n",
    ">\n",
    "\n",
    "- `transactionsDf.withColumn(\"storeId\", convert(\"storeId\", \"string\"))`\n",
    "- `transactionsDf.withColumn(\"storeId\", col(\"storeId\", \"string\"))`\n",
    "- `transactionsDf.withColumn(\"storeId\", col(\"storeId\").convert(\"string\"))`\n",
    "- `transactionsDf.withColumn(\"storeId\", col(\"storeId\").cast(\"string\"))`\n",
    "- `transactionsDf.withColumn(\"storeId\", convert(\"storeId\").as(\"string\"))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transactionId: integer (nullable = true)\n",
      " |-- predError: integer (nullable = true)\n",
      " |-- value: integer (nullable = true)\n",
      " |-- storeId: string (nullable = true)\n",
      " |-- productId: integer (nullable = true)\n",
      " |-- f: integer (nullable = true)\n",
      " |-- transactionDate: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionsDf.withColumn(\"storeId\", col(\"storeId\").cast(\"string\")).printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NameError: name 'convert' is not defined\n",
    "transactionsDf.withColumn(\"storeId\", convert(\"storeId\", \"string\"))\n",
    "\n",
    "# TypeError: _() takes 1 positional argument but 2 were given\n",
    "transactionsDf.withColumn(\"storeId\", col(\"storeId\", \"string\"))\n",
    "\n",
    "# TypeError: 'Column' object is not callable\n",
    "transactionsDf.withColumn(\"storeId\", col(\"storeId\").convert(\"string\"))\n",
    "\n",
    "# SyntaxError: invalid syntax\n",
    "transactionsDf.withColumn(\"storeId\", convert(\"storeId\").as(\"string\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks returns a DataFrame with a new column salary_increment and all previously existing columns.\n",
    ">\n",
    "- `df.selectExpr(\"*\", \"salary * 0.15\")`\n",
    "- `df.withColumn(\"salary_increment\", expr(\"salary * 0.15\"))`\n",
    "- `df.withColumn(\"salary_increment\", \"salary * 0.15\")`\n",
    "- `df.selectExpr(\"*\", \"salary * 0.15 as salary_increment\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+---------------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|(salary * 0.15)|\n",
      "+---------+----------+--------+----------+------+------+---------------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000|         450.00|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|         600.00|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|         600.00|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|         600.00|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|          -0.15|\n",
      "+---------+----------+--------+----------+------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"*\", \"salary * 0.15\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+----------------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|salary_increment|\n",
      "+---------+----------+--------+----------+------+------+----------------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000|          450.00|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|          600.00|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|          600.00|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|          600.00|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|           -0.15|\n",
      "+---------+----------+--------+----------+------+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"salary_increment\", expr(\"salary * 0.15\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+----------------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|salary_increment|\n",
      "+---------+----------+--------+----------+------+------+----------------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000|          450.00|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|          600.00|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|          600.00|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|          600.00|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|           -0.15|\n",
      "+---------+----------+--------+----------+------+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"*\", \"salary * 0.15 as salary_increment\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AssertionError: col should be Column\n",
    "df.withColumn(\"salary_increment\", \"salary * 0.15\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a DataFrame as shown below.\n",
    ">\n",
    "- `+——-+—-+———-+`\n",
    "- `|BatchID|Year|CourseName|`\n",
    "- `+——-+—-+———-+`\n",
    "- `| X1 |2020| Scala |`\n",
    "- `| X2 |2020| Python |`\n",
    "- `| X3 |null| Java |`\n",
    "- `| X4 |2021| Scala |`\n",
    "- `| X5 |null| Python |`\n",
    "- `| X6 |2021| Spark |`\n",
    "- `+——-+—-+———-+`\n",
    ">\n",
    "You want to transform the Year column and replace all nulls with the value 2021. Choose the correct option from the given code blocks.\n",
    ">\n",
    "- `df.withColumn(\"Year\", coalesce(col(\"Year\"), \"2021\"))`\n",
    "- `df.withColumn(\"Year\", coalesce(col(\"Year\"), lit(\"2021\")))`\n",
    "- `df.withColumn(\"Year\", coalesce(col(\"Year\"), col(\"2021\")))`\n",
    "- `df.withColumn(\"Year\", coalesce(col(\"Year\"), expr(\"2021\")))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- BatchID: string (nullable = true)\n",
      " |-- Year: long (nullable = true)\n",
      " |-- CourseName: string (nullable = true)\n",
      "\n",
      "+-------+----+----------+\n",
      "|BatchID|Year|CourseName|\n",
      "+-------+----+----------+\n",
      "|     X1|2020|     Scala|\n",
      "|     X2|2020|    Python|\n",
      "|     X3|null|      Java|\n",
      "|     X4|2021|     Scala|\n",
      "|     X5|null|    Python|\n",
      "|     X6|2021|     Spark|\n",
      "+-------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "        ('X1',2020,'Scala'),\n",
    "        ('X2',2020,'Python'),\n",
    "        ('X3',None,'Java'),\n",
    "        ('X4',2021,'Scala'),\n",
    "        ('X5',None,'Python'),\n",
    "        ('X6',2021,'Spark')]\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema = ['BatchID','Year','CourseName'])\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+\n",
      "|BatchID|Year|CourseName|\n",
      "+-------+----+----------+\n",
      "|     X1|2020|     Scala|\n",
      "|     X2|2020|    Python|\n",
      "|     X3|2021|      Java|\n",
      "|     X4|2021|     Scala|\n",
      "|     X5|2021|    Python|\n",
      "|     X6|2021|     Spark|\n",
      "+-------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Year\", expr(\"coalesce(Year, '2021')\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+\n",
      "|BatchID|Year|CourseName|\n",
      "+-------+----+----------+\n",
      "|     X1|2020|     Scala|\n",
      "|     X2|2020|    Python|\n",
      "|     X3|2021|      Java|\n",
      "|     X4|2021|     Scala|\n",
      "|     X5|2021|    Python|\n",
      "|     X6|2021|     Spark|\n",
      "+-------+----+----------+\n",
      "\n",
      "+-------+----+----------+\n",
      "|BatchID|Year|CourseName|\n",
      "+-------+----+----------+\n",
      "|     X1|2020|     Scala|\n",
      "|     X2|2020|    Python|\n",
      "|     X3|2021|      Java|\n",
      "|     X4|2021|     Scala|\n",
      "|     X5|2021|    Python|\n",
      "|     X6|2021|     Spark|\n",
      "+-------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df.withColumn(\"Year\", expr(\"coalesce(Year, '2021')\")).show()\n",
    "df.withColumn(\"Year\", coalesce(col(\"Year\"), lit(\"2021\"))).show()\n",
    "df.withColumn(\"Year\", coalesce(col(\"Year\"), expr(\"2021\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+\n",
      "|BatchID|Year|CourseName|\n",
      "+-------+----+----------+\n",
      "|     X1|2020|     Scala|\n",
      "|     X2|2020|    Python|\n",
      "|     X3|2021|      Java|\n",
      "|     X4|2021|     Scala|\n",
      "|     X5|2021|    Python|\n",
      "|     X6|2021|     Spark|\n",
      "+-------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Year\", expr(\"ifnull(Year, '2021')\")).show()\n",
    "#df.withColumn(\"Year\", ifnull(col(\"Year\"), \"2021\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"Year\", coalesce(col(\"Year\"), expr(\"2021\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnalysisException: cannot resolve '`2021`' given input columns: [BatchID, CourseName, Year]\n",
    "df.withColumn(\"Year\", coalesce(col(\"Year\"), \"2021\"))\n",
    "\n",
    "# AnalysisException: cannot resolve '`2021`' given input columns: [BatchID, CourseName, Year]\n",
    "df.withColumn(\"Year\", coalesce(col(\"Year\"), col(\"2021\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which function will you use to add a new field in your DataFrame with a current timestamp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+-----------------------+\n",
      "|firstname|middlename|lastname|dob       |gender|salary|now                    |\n",
      "+---------+----------+--------+----------+------+------+-----------------------+\n",
      "|James    |          |Smith   |1991-04-01|M     |3000  |2021-11-25 14:27:15.822|\n",
      "|Michael  |Rose      |        |2000-05-19|M     |4000  |2021-11-25 14:27:15.822|\n",
      "|Robert   |          |Williams|1978-09-05|M     |4000  |2021-11-25 14:27:15.822|\n",
      "|Maria    |Anne      |Jones   |1967-12-01|F     |4000  |2021-11-25 14:27:15.822|\n",
      "|Jen      |Mary      |Brown   |1980-02-17|F     |-1    |2021-11-25 14:27:15.822|\n",
      "+---------+----------+--------+----------+------+------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"now\", current_timestamp()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'now' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c95ab95b5686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"now\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'now' is not defined"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"now\", now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'Year' given input columns: [dob, firstname, gender, lastname, middlename, salary]; line 1 pos 7;\n'Project [firstname#644, middlename#645, lastname#646, dob#647, gender#648, salary#649L, 'ifnull('Year, 2021) AS Year#693]\n+- LogicalRDD [firstname#644, middlename#645, lastname#646, dob#647, gender#648, salary#649L], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-024c0fc9da15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Year\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ifnull(Year, '2021')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2478\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1310\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'Year' given input columns: [dob, firstname, gender, lastname, middlename, salary]; line 1 pos 7;\n'Project [firstname#644, middlename#645, lastname#646, dob#647, gender#648, salary#649L, 'ifnull('Year, 2021) AS Year#693]\n+- LogicalRDD [firstname#644, middlename#645, lastname#646, dob#647, gender#648, salary#649L], false\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Year\", expr(\"ifnull(Year, '2021')\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6ad6cad6e86b8f8ebaedbe94ebc31d728d6c0d8223a99e9449734cfa4d7995"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
