{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOIN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"example-join\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------+\n",
      "|emp_id|    name|emp_dept_id|\n",
      "+------+--------+-----------+\n",
      "|     1|   Smith|         10|\n",
      "|     2|    Rose|         20|\n",
      "|     3|Williams|         10|\n",
      "|     4|   Jones|         30|\n",
      "+------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Emp Table\n",
    "empData = [(1,\"Smith\",10), (2,\"Rose\",20),(3,\"Williams\",10), (4,\"Jones\",30)]\n",
    "\n",
    "empColumns = [\"emp_id\",\"name\",\"emp_dept_id\"]\n",
    "\n",
    "empDF = spark.createDataFrame(empData,empColumns)\n",
    "empDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|  Finance|     10|\n",
      "|Marketing|     20|\n",
      "|    Sales|     30|\n",
      "|       IT|     40|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dept Table\n",
    "deptData = [(\"Finance\",10), (\"Marketing\",20), (\"Sales\",30),(\"IT\",40)]\n",
    "\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "\n",
    "deptDF=spark.createDataFrame(deptData,deptColumns)  \n",
    "deptDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+--------+-----+\n",
      "|emp_id|       addline1|    city|state|\n",
      "+------+---------------+--------+-----+\n",
      "|     1|   1523 Main St|     SFO|   CA|\n",
      "|     2| 3453 Orange St|     SFO|   NY|\n",
      "|     3|   34 Warner St|  Jersey|   NJ|\n",
      "|     4|221 Cavalier St|  Newark|   DE|\n",
      "|     5|  789 Walnut St|Sandiago|   CA|\n",
      "+------+---------------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Address Table\n",
    "addData=[(1,\"1523 Main St\",\"SFO\",\"CA\"),\n",
    "         (2,\"3453 Orange St\",\"SFO\",\"NY\"),\n",
    "         (3,\"34 Warner St\",\"Jersey\",\"NJ\"),\n",
    "         (4,\"221 Cavalier St\",\"Newark\",\"DE\"),\n",
    "         (5,\"789 Walnut St\",\"Sandiago\",\"CA\")]\n",
    "\n",
    "addColumns = [\"emp_id\", \"addline1\", \"city\", \"state\"]\n",
    "\n",
    "addDF = spark.createDataFrame(addData,addColumns)\n",
    "addDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark Join Two DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------+------+---------------+------+-----+\n",
      "|emp_id|    name|emp_dept_id|emp_id|       addline1|  city|state|\n",
      "+------+--------+-----------+------+---------------+------+-----+\n",
      "|     1|   Smith|         10|     1|   1523 Main St|   SFO|   CA|\n",
      "|     3|Williams|         10|     3|   34 Warner St|Jersey|   NJ|\n",
      "|     2|    Rose|         20|     2| 3453 Orange St|   SFO|   NY|\n",
      "|     4|   Jones|         30|     4|221 Cavalier St|Newark|   DE|\n",
      "+------+--------+-----------+------+---------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join(right, joinExprs, joinType)\n",
    "# join(right)\n",
    "\n",
    "empDF.join(addDF, empDF[\"emp_id\"] == addDF[\"emp_id\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------+---------------+------+-----+\n",
      "|emp_id|    name|emp_dept_id|       addline1|  city|state|\n",
      "+------+--------+-----------+---------------+------+-----+\n",
      "|     1|   Smith|         10|   1523 Main St|   SFO|   CA|\n",
      "|     3|Williams|         10|   34 Warner St|Jersey|   NJ|\n",
      "|     2|    Rose|         20| 3453 Orange St|   SFO|   NY|\n",
      "|     4|   Jones|         30|221 Cavalier St|Newark|   DE|\n",
      "+------+--------+-----------+---------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop Duplicate Columns After Join\n",
    "empDF.join(addDF,[\"emp_id\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------+---------------+------+-----+---------+-------+\n",
      "|emp_id|    name|emp_dept_id|       addline1|  city|state|dept_name|dept_id|\n",
      "+------+--------+-----------+---------------+------+-----+---------+-------+\n",
      "|     1|   Smith|         10|   1523 Main St|   SFO|   CA|  Finance|     10|\n",
      "|     3|Williams|         10|   34 Warner St|Jersey|   NJ|  Finance|     10|\n",
      "|     4|   Jones|         30|221 Cavalier St|Newark|   DE|    Sales|     30|\n",
      "|     2|    Rose|         20| 3453 Orange St|   SFO|   NY|Marketing|     20|\n",
      "+------+--------+-----------+---------------+------+-----+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Join Multiple DataFrames by chaining\n",
    "empDF.join(addDF,[\"emp_id\"]) \\\n",
    "     .join(deptDF,empDF[\"emp_dept_id\"] == deptDF[\"dept_id\"]) \\\n",
    "     .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------+---------+-------+------+---------------+------+-----+\n",
      "|emp_id|    name|emp_dept_id|dept_name|dept_id|emp_id|       addline1|  city|state|\n",
      "+------+--------+-----------+---------+-------+------+---------------+------+-----+\n",
      "|     1|   Smith|         10|  Finance|     10|     1|   1523 Main St|   SFO|   CA|\n",
      "|     3|Williams|         10|  Finance|     10|     3|   34 Warner St|Jersey|   NJ|\n",
      "|     2|    Rose|         20|Marketing|     20|     2| 3453 Orange St|   SFO|   NY|\n",
      "|     4|   Jones|         30|    Sales|     30|     4|221 Cavalier St|Newark|   DE|\n",
      "+------+--------+-----------+---------+-------+------+---------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Where for Join Condition\n",
    "empDF.join(deptDF).where(empDF[\"emp_dept_id\"] == deptDF[\"dept_id\"]) \\\n",
    "    .join(addDF).where(empDF[\"emp_id\"] == addDF[\"emp_id\"]) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------+---------+-------+------+---------------+------+-----+\n",
      "|emp_id|    name|emp_dept_id|dept_name|dept_id|emp_id|       addline1|  city|state|\n",
      "+------+--------+-----------+---------+-------+------+---------------+------+-----+\n",
      "|     1|   Smith|         10|  Finance|     10|     1|   1523 Main St|   SFO|   CA|\n",
      "|     3|Williams|         10|  Finance|     10|     3|   34 Warner St|Jersey|   NJ|\n",
      "|     2|    Rose|         20|Marketing|     20|     2| 3453 Orange St|   SFO|   NY|\n",
      "|     4|   Jones|         30|    Sales|     30|     4|221 Cavalier St|Newark|   DE|\n",
      "+------+--------+-----------+---------+-------+------+---------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Filter for Join Condition\n",
    "empDF.join(deptDF).filter(empDF[\"emp_dept_id\"] == deptDF[\"dept_id\"]) \\\n",
    "    .join(addDF).filter(empDF[\"emp_id\"] == addDF[\"emp_id\"]) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------+---------+-------+------+---------------+------+-----+\n",
      "|emp_id|    name|emp_dept_id|dept_name|dept_id|emp_id|       addline1|  city|state|\n",
      "+------+--------+-----------+---------+-------+------+---------------+------+-----+\n",
      "|     1|   Smith|         10|  Finance|     10|     1|   1523 Main St|   SFO|   CA|\n",
      "|     3|Williams|         10|  Finance|     10|     3|   34 Warner St|Jersey|   NJ|\n",
      "|     2|    Rose|         20|Marketing|     20|     2| 3453 Orange St|   SFO|   NY|\n",
      "|     4|   Jones|         30|    Sales|     30|     4|221 Cavalier St|Newark|   DE|\n",
      "+------+--------+-----------+---------+-------+------+---------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "empDF.createOrReplaceTempView(\"emp\")\n",
    "deptDF.createOrReplaceTempView(\"dept\")\n",
    "addDF.createOrReplaceTempView(\"add\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "             select * \n",
    "               from emp e, dept d, add a\n",
    "              where e.emp_dept_id == d.dept_id \n",
    "                and e.emp_id == a.emp_id\n",
    "         \"\"\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+\n",
      "| A1| A2| B1| B2|\n",
      "+---+---+---+---+\n",
      "|  2|  B|  2|  B|\n",
      "+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PySpark Join With Multiple Columns & Conditions\n",
    "df1 = spark.createDataFrame([(1, \"A\"), (2, \"B\"), (3, \"C\")], [\"A1\", \"A2\"])\n",
    "\n",
    "df2 = spark.createDataFrame([(1, \"F\"), (2, \"B\")], [\"B1\", \"B2\"])\n",
    "\n",
    "df = df1.join(df2, (df1.A1 == df2.B1) & (df1.A2 == df2.B2))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6ad6cad6e86b8f8ebaedbe94ebc31d728d6c0d8223a99e9449734cfa4d7995"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
