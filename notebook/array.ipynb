{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# array() + array_contains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import array_contains, col, array, array_contains, explode\n",
    "from pyspark.sql.types import StringType, ArrayType, StructType, StructField, FloatType\n",
    "from pyspark.sql import functions as F\n",
    "from functools import reduce\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"example-07\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- languagesAtSchool: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- languagesAtWork: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- currentState: string (nullable = true)\n",
      " |-- previousState: string (nullable = true)\n",
      " |-- grade: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n",
      "+----------------+------------------+---------------+------------+-------------+--------------------+\n",
      "|            name| languagesAtSchool|languagesAtWork|currentState|previousState|               grade|\n",
      "+----------------+------------------+---------------+------------+-------------+--------------------+\n",
      "|    James,,Smith|[Java, Scala, C++]|  [Spark, Java]|          OH|           CA|[1.0, 2.1, 3.2, 4...|\n",
      "|   Michael,Rose,|[Spark, Java, C++]|  [Spark, Java]|          NY|           NJ|[2.0, 3.1, 4.2, 5...|\n",
      "|Robert,,Williams|      [CSharp, VB]|[Spark, Python]|          UT|           NV|[3.0, 4.1, 5.2, 6...|\n",
      "+----------------+------------------+---------------+------------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arrayCol = ArrayType(StringType(),False)\n",
    "\n",
    "data = [(\"James,,Smith\", [\"Java\",\"Scala\",\"C++\"], [\"Spark\",\"Java\"], \"OH\", \"CA\", [1.0,2.1,3.2,4.3,5.4]),\n",
    "        (\"Michael,Rose,\", [\"Spark\",\"Java\",\"C++\"], [\"Spark\",\"Java\"], \"NY\", \"NJ\",[2.0,3.1,4.2,5.3,6.4]),\n",
    "        (\"Robert,,Williams\", [\"CSharp\",\"VB\"], [\"Spark\",\"Python\"], \"UT\", \"NV\",[3.0,4.1,5.2,6.3,7.4])]\n",
    "\n",
    "schema = StructType([ \n",
    "    StructField(\"name\",StringType(),True), \n",
    "    StructField(\"languagesAtSchool\",ArrayType(StringType()),True), \n",
    "    StructField(\"languagesAtWork\",ArrayType(StringType()),True), \n",
    "    StructField(\"currentState\", StringType(), True), \n",
    "    StructField(\"previousState\", StringType(), True),\n",
    "    StructField(\"grade\",ArrayType(FloatType()),True), \n",
    "  ])\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+------------------+-----------------+-----------------+-----------------+\n",
      "|            name|average_1|         average_2|        average_3|        average_4|        average_5|\n",
      "+----------------+---------+------------------+-----------------+-----------------+-----------------+\n",
      "|    James,,Smith|      1.0|2.0999999046325684|3.200000047683716|4.300000190734863|5.400000095367432|\n",
      "|   Michael,Rose,|      2.0|3.0999999046325684|4.199999809265137|5.300000190734863|6.400000095367432|\n",
      "|Robert,,Williams|      3.0| 4.099999904632568|5.199999809265137|6.300000190734863|7.400000095367432|\n",
      "+----------------+---------+------------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = df.select(F.max(F.size('grade')).alias('n')).first().n\n",
    "df1 = df.select('name', *[F.col('grade')[i].alias('val_{}'.format(i+1)) for i in range(n)])\n",
    "df2 = df1.groupby('name').agg(*[ F.mean('val_{}'.format(i+1)).alias('average_{}'.format(i+1)) for i in range(n)])\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+\n",
      "|            name|           average|\n",
      "+----------------+------------------+\n",
      "|    James,,Smith|               1.0|\n",
      "|   Michael,Rose,|               2.0|\n",
      "|Robert,,Williams|               3.0|\n",
      "|    James,,Smith|2.0999999046325684|\n",
      "|   Michael,Rose,|3.0999999046325684|\n",
      "|Robert,,Williams| 4.099999904632568|\n",
      "|    James,,Smith| 3.200000047683716|\n",
      "|   Michael,Rose,| 4.199999809265137|\n",
      "|Robert,,Williams| 5.199999809265137|\n",
      "|    James,,Smith| 4.300000190734863|\n",
      "|   Michael,Rose,| 5.300000190734863|\n",
      "|Robert,,Williams| 6.300000190734863|\n",
      "|    James,,Smith| 5.400000095367432|\n",
      "|   Michael,Rose,| 6.400000095367432|\n",
      "|Robert,,Williams| 7.400000095367432|\n",
      "+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new = reduce(lambda x,y: x.union(y), [\n",
    "    df2.select('name', F.col('average_{}'.format(i+1)).alias('average')) \\\n",
    "       .dropna(subset=['average']) for i in range(n)\n",
    "])\n",
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|            name|  States|\n",
      "+----------------+--------+\n",
      "|    James,,Smith|[OH, CA]|\n",
      "|   Michael,Rose,|[NY, NJ]|\n",
      "|Robert,,Williams|[UT, NV]|\n",
      "+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# array()\n",
    "df.select(df.name,array(df.currentState,df.previousState).alias(\"States\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+\n",
      "|            name|array_contains|\n",
      "+----------------+--------------+\n",
      "|    James,,Smith|          true|\n",
      "|   Michael,Rose,|          true|\n",
      "|Robert,,Williams|         false|\n",
      "+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# array_contains()\n",
    "df.select(df.name, array_contains(df.languagesAtSchool,\"Java\").alias(\"array_contains\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block shown below should return a DataFrame with two columns, itemId and col. \n",
    "\n",
    "In this DataFrame, for each element in column attributes of DataFrame itemDf there should be a separate row in which the column itemId contains the associated itemId from DataFrame itemsDf. \n",
    "\n",
    "The new DataFrame should only contain rows for rows in DataFrame itemsDf in which the column attributes contains the element cozy.\n",
    "\n",
    "A sample of DataFrame itemsDf is below.\n",
    "+——+—————————–+——————-+\n",
    "|itemId|attributes |supplier |\n",
    "+——+—————————–+——————-+\n",
    "|1 |[blue, winter, cozy] |Sports Company Inc.|\n",
    "|2 |[red, summer, fresh, cooling]|YetiX |\n",
    "|3 |[green, summer, travel] |Sports Company Inc.|\n",
    "+——+—————————–+——————-+\n",
    "\n",
    "Code block:\n",
    "itemsDf.__1__(__2__).__3__(__4__, __5__(__6__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- itemId: string (nullable = true)\n",
      " |-- attributes: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- supplier: string (nullable = true)\n",
      "\n",
      "+------+--------------------+-------------------+\n",
      "|itemId|          attributes|           supplier|\n",
      "+------+--------------------+-------------------+\n",
      "|     1|[blue, winter, cozy]|Sports Company Inc.|\n",
      "|     2|[red, summer, fre...|              YetiX|\n",
      "|     3|[green, summer, t...|Sports Company Inc.|\n",
      "+------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "        ('1',['blue', 'winter', 'cozy'],'Sports Company Inc.'),\n",
    "        ('2',['red', 'summer', 'fresh', 'cooling'],'YetiX'),\n",
    "        ('3',['green', 'summer', 'travel'],'Sports Company Inc.')]\n",
    "\n",
    "itemsDf = spark.createDataFrame(data=data, schema = ['itemId','attributes','supplier'])\n",
    "itemsDf.printSchema()\n",
    "itemsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[itemId: string, col: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemsDf.filter(\"array_contains(attributes, 'cozy')\").select(\"itemId\", explode(\"attributes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "map() must have at least two arguments.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-32756fbe80ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mitemsDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"array_contains(attributes, 'cozy')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"itemId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"attributes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: map() must have at least two arguments."
     ]
    }
   ],
   "source": [
    "itemsDf.filter(\"array_contains(attributes, 'cozy')\").select(\"itemId\", map(\"attributes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6ad6cad6e86b8f8ebaedbe94ebc31d728d6c0d8223a99e9449734cfa4d7995"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
