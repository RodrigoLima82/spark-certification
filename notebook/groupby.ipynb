{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GROUPBY()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"example-groupby\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [(\"David\", \"Account\", \"United States\", \"6500\"),\n",
    "             (\"Ravi\", \"Account\", \"India\", \"5500\"),\n",
    "             (\"John\", \"Software\", \"India\", \"6500\"),\n",
    "             (\"Rosy\", \"Software\", \"India\", \"8200\"),\n",
    "             (\"Abdul\", \"Support\", \"Brazil\", \"4800\")]\n",
    " \n",
    "df = spark.createDataFrame(data_list).toDF(\"name\", \"department\", \"country\", \"salary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-----------+-----------+\n",
      "|department|      country|NumEmployee|TotalSalary|\n",
      "+----------+-------------+-----------+-----------+\n",
      "|   Account|        India|          1|     5500.0|\n",
      "|   Support|       Brazil|          1|     4800.0|\n",
      "|   Account|United States|          1|     6500.0|\n",
      "|  Software|        India|          2|    14700.0|\n",
      "+----------+-------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"department\", \"country\") \\\n",
    "  .agg(expr(\"count(*) as NumEmployee\"), expr(\"sum(salary) as TotalSalary\")) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "|key|count|sum|\n",
      "+---+-----+---+\n",
      "|  1|    1|  1|\n",
      "|  6|    1|  6|\n",
      "|  3|    2|  6|\n",
      "|  4|    1|  4|\n",
      "|  2|    3|  6|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mylist = [1002, 3001, 4002, 2003, 2002, 3004, 1003, 4006]\n",
    "df = spark.createDataFrame(mylist, IntegerType()).toDF(\"value\")\n",
    "df.withColumn(\"key\", col(\"value\") % 1000) \\\n",
    "  .groupBy(\"key\") \\\n",
    "  .agg(expr(\"count(key) as count\"), expr(\"sum(key) as sum\")) \\\n",
    "  .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|count|sum|\n",
      "+-----+---+\n",
      "|    1|  6|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"key\", col(\"value\") % 1000) \\\n",
    "  .groupBy(\"key\") \\\n",
    "  .agg(expr(\"count(key) as count\"), expr(\"sum(key) as sum\")) \\\n",
    "  .orderBy(col(\"key\").desc()) \\\n",
    "  .limit(1) \\\n",
    "  .select(\"count\", \"sum\") \\\n",
    "  .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------+\n",
      "|      country|department|count(1)|\n",
      "+-------------+----------+--------+\n",
      "|        India|   Account|       1|\n",
      "|United States|   Account|       1|\n",
      "|        India|  Software|       2|\n",
      "|       Brazil|   Support|       1|\n",
      "+-------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"country\", \"department\").agg(expr(\"count(*)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+\n",
      "|      country|department|count|\n",
      "+-------------+----------+-----+\n",
      "|        India|   Account|    1|\n",
      "|United States|   Account|    1|\n",
      "|        India|  Software|    2|\n",
      "|       Brazil|   Support|    1|\n",
      "+-------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"country\", \"department\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-----+\n",
      "|department|      country|count|\n",
      "+----------+-------------+-----+\n",
      "|   Account|        India|    1|\n",
      "|   Support|       Brazil|    1|\n",
      "|   Account|United States|    1|\n",
      "|  Software|        India|    2|\n",
      "+----------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"department\", \"country\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mismatched input ',' expecting {<EOF>,\n",
    "df.groupBy(expr(\"country, department\")).count().show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6ad6cad6e86b8f8ebaedbe94ebc31d728d6c0d8223a99e9449734cfa4d7995"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
